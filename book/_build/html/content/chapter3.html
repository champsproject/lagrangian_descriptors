

<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>The Method of Lagrangian Descriptors &#8212; Lagrangian Descriptors</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/all.min.css" integrity="sha384-KA6wR/X5RY4zFAHpv/CnoG2UW1uogYfdnP67Uv7eULvTveboZJg0qUpmJZb5VqzN" crossorigin="anonymous">
    <link href="../_static/css/index.css" rel="stylesheet">
    <link rel="stylesheet" href="../_static/sphinx-book-theme.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/jupyter-sphinx.css" />
    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/sphinx-book-theme.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/language_data.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/mystnb.js"></script>
    <script src="../_static/sphinx-book-theme.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.18.0/dist/embed-amd.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Computing the Lagrangian Descriptors of Nonlinear Dynamical Systems" href="examples.html" />
    <link rel="prev" title="An Informal Introduction to Ideas Related to KAM (Kolmogorov-Arnold-Moser) Theory" href="chapter2_2.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="docsearch:language" content="en">



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../index.html">
  
  <img src="../_static/champs_logo.jpg" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">Lagrangian Descriptors</h1>
  
</a>
</div>

<form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>

<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  
  <ul class="nav sidenav_l1">
  <li class="">
    <a href="../intro.html">Authors</a>
  </li>
<li class="navbar-special">
<p class="margin-caption">Chapter 1</p>
</li>
  <li class="">
    <a href="chapter1_1.html">The Setting: Hamiltonian Dynamics on Phase Space</a>
  </li>
  <li class="">
    <a href="chapter1_2.html">Hamiltonian flows and symplectic maps</a>
  </li>
<li class="navbar-special">
<p class="margin-caption">Chapter 2</p>
</li>
  <li class="">
    <a href="chapter2_1.html">The Hyperbolic setting</a>
  </li>
  <li class="">
    <a href="chapter2_2.html">An Informal Introduction to  Ideas Related to KAM (Kolmogorov-Arnold-Moser) Theory</a>
  </li>
<li class="navbar-special">
<p class="margin-caption">Chapter 3</p>
</li>
  <li class="active">
    <a href="">The Method of Lagrangian Descriptors</a>
  </li>
<li class="navbar-special">
<p class="margin-caption">Examples</p>
</li>
  <li class="">
    <a href="examples.html">Computing the Lagrangian Descriptors of Nonlinear Dynamical Systems</a>
  </li>
  <li class="">
    <a href="https://github.com/champsproject/lagrangian_descriptors">GitHub repository<i class="fas fa-external-link-alt"></i></a>
  </li>
</ul>
</nav>

 <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        <div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    
    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/content/chapter3.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
    
</div>
        <!-- Source interaction buttons -->


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/champsproject/lagrangian_descriptors/master?filepath=book%2Fcontent/v2/gh/champsproject/lagrangian_descriptors/master?urlpath=tree/content/chapter3.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

    </div>
    <div class="d-none d-md-block col-md-2 bd-toc show">
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="nav section-nav flex-column">
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#introduction" class="nav-link">Introduction</a><ul class="nav section-nav flex-column">
                
        <li class="nav-item toc-entry toc-h3">
            <a href="#lagrangian-descriptors-versus-poincar-e-maps" class="nav-link">Lagrangian Descriptors versus Poincar’e Maps</a>
        </li>
    
        <li class="nav-item toc-entry toc-h3">
            <a href="#autonomous-hamiltonian-vector-fields" class="nav-link">Autonomous Hamiltonian vector fields</a>
        </li>
    
        <li class="nav-item toc-entry toc-h3">
            <a href="#nonautonomous-hamiltonian-vector-fields" class="nav-link">Nonautonomous Hamiltonian vector fields</a>
        </li>
    
            </ul>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#formulations-for-lagrangian-descriptors" class="nav-link">Formulations for Lagrangian Descriptors</a><ul class="nav section-nav flex-column">
                
        <li class="nav-item toc-entry toc-h3">
            <a href="#the-arclength-definition" class="nav-link">The Arclength Definition</a>
        </li>
    
        <li class="nav-item toc-entry toc-h3">
            <a href="#the-p-norm-definition" class="nav-link">The p-norm Definition</a>
        </li>
    
        <li class="nav-item toc-entry toc-h3">
            <a href="#lagrangian-descriptors-based-on-the-classical-action" class="nav-link">Lagrangian Descriptors Based on the Classical Action</a><ul class="nav section-nav flex-column">
                
        <li class="nav-item toc-entry toc-h4">
            <a href="#one-degree-of-freedom-autonomous-hamiltonian-systems" class="nav-link">One Degree-of-Freedom Autonomous Hamiltonian Systems</a>
        </li>
    
        <li class="nav-item toc-entry toc-h4">
            <a href="#n-degree-of-freedom-autonomous-hamiltonian-systems" class="nav-link">n Degree-of-Freedom Autonomous Hamiltonian Systems</a>
        </li>
    
            </ul>
        </li>
    
            </ul>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#variable-integration-time-lagrangian-descriptors" class="nav-link">Variable Integration Time Lagrangian Descriptors</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#examples" class="nav-link">Examples</a><ul class="nav section-nav flex-column">
                
        <li class="nav-item toc-entry toc-h3">
            <a href="#the-duffing-oscillator" class="nav-link">The Duffing Oscillator</a>
        </li>
    
        <li class="nav-item toc-entry toc-h3">
            <a href="#the-linear-hamiltonian-saddle-with-2-dof" class="nav-link">The linear Hamiltonian saddle with 2 DoF</a>
        </li>
    
        <li class="nav-item toc-entry toc-h3">
            <a href="#the-cubic-potential" class="nav-link">The Cubic Potential</a>
        </li>
    
        <li class="nav-item toc-entry toc-h3">
            <a href="#the-h-enon-heiles-hamiltonian-system" class="nav-link">The H’enon-Heiles Hamiltonian System</a>
        </li>
    
            </ul>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#stochastic-lagrangian-descriptors" class="nav-link">Stochastic Lagrangian Descriptors</a><ul class="nav section-nav flex-column">
                
        <li class="nav-item toc-entry toc-h3">
            <a href="#preliminary-concepts" class="nav-link">Preliminary concepts</a>
        </li>
    
        <li class="nav-item toc-entry toc-h3">
            <a href="#the-stochastic-lagrangian-descriptor" class="nav-link">The stochastic Lagrangian descriptor</a>
        </li>
    
            </ul>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#numerical-simulation-of-the-stochastic-lagrangian-descriptor" class="nav-link">Numerical Simulation of the Stochastic Lagrangian Descriptor</a><ul class="nav section-nav flex-column">
                
        <li class="nav-item toc-entry toc-h3">
            <a href="#the-noisy-saddle" class="nav-link">The noisy saddle</a>
        </li>
    
        <li class="nav-item toc-entry toc-h3">
            <a href="#the-stochastically-forced-duffing-oscillator" class="nav-link">The Stochastically forced Duffing Oscillator</a>
        </li>
    
            </ul>
        </li>
    
    </ul>
</nav>


    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="the-method-of-lagrangian-descriptors">
<h1>The Method of Lagrangian Descriptors<a class="headerlink" href="#the-method-of-lagrangian-descriptors" title="Permalink to this headline">¶</a></h1>
<div class="section" id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Permalink to this headline">¶</a></h2>
<p>\label{sec:LDs}</p>
<p>One of the biggest challenges of dynamical systems theory or nonlinear dynamics is the development of mathematical techniques that provide us with the capability of exploring  transport in phase space. Since the early 1900, the idea of pursuing a qualitative description of the solutions of differential equations, which emerged from the pioneering work carried out by Henri Poincar’e on the three body problem of celestial mechanics \cite{hp1890}, has had a profound impact on our understanding of the nonlinear character of natural phenomena. The qualitative theory of dynamical systems has now been widely embraced by the scientific community.</p>
<p>The goal of this section is to describe the details behind the method of Lagrangian descriptors. This simple and powerful technique unveils regions with qualitatively distinct dynamical behavior, the boundaries of which consist of invariant manifolds. In a procedure that is best characterised as \textit{phase space tomography}, we can use low-dimensional slices we are able to completely reconstruct the intricate geometry of underlying invariant manifolds that governs phase space transport.</p>
<p>Consider a general time-dependent dynamical system given by the equation:</p>
<p>\begin{equation}
\dfrac{d\mathbf{x}}{dt} = \mathbf{f}(\mathbf{x},t) ;,\quad \mathbf{x} \in \mathbb{R}^{n} ;,; t \in \mathbb{R} ;,
\label{eq:gtp_dynSys}
\end{equation}</p>
<p>where the vector field <span class="math notranslate nohighlight">\(\mathbf{f}(\mathbf{x},t)\)</span> is assumed to be sufficiently smooth both in space and time. The vector field <span class="math notranslate nohighlight">\(\mathbf{f}\)</span> can be prescribed by an analytical model or given from numerical simulations as a discrete spatio-temporal data set. For instance, the vector field could represent the velocity field of oceanic or atmospheric currents obtained from satellite measurements or from the numerical solution of geophysical models. In the context of chemical reaction dynamics, the vector field could be the result of molecular dynamics simulations. For any initial condition <span class="math notranslate nohighlight">\(\mathbf{x}(t_0) = \mathbf{x}_0\)</span>, the system of first order nonlinear differential equations given in Eq. \eqref{eq:gtp_dynSys} has a unique solution represented by the trajectory that starts from that initial point <span class="math notranslate nohighlight">\(\mathbf{x}_0\)</span> at time <span class="math notranslate nohighlight">\(t_0\)</span>.</p>
<p>Since all the information that determines the behavior and fate of the trajectories for the dynamical system is encoded in the initial conditions (ICs) from which they are generated, we are interested in the development of a mathematical technique with the capability of revealing the underlying geometrical structures that govern the transport in phase space.</p>
<p>Lagrangian descriptors (LDs) provide us with a simple and effective way of addressing this challenging task, because it is formulated as a scalar trajectory-diagnostic tool based on trajectories. The elegant idea behind this methodology is that it assigns to each initial condition selected in the phase space a positive number, which is calculated by accumulating the values taken by a predefined positive function along the trajectory when the system is evolved forward and backward for some time interval. The positive function of the phase space variables that is used to define different types of LD might have some geometrical or physical relevance, but this is not a necessary requirement for the implementation of the method. This approach is remarkably similar to the visualization techniques used in laboratory experiments to uncover the beautiful patterns of fluid flow structures with the help of drops of dye injected into the moving fluid \cite{chien1986}. In fact, the development of LDs was originally inspired by the desire to explain the intricate geometrical flow patterns that are responsible for governing transport and mixing processes in Geophysical flows. The method was first introduced a decade ago based on the arclength of fluid parcel trajectories \cite{madrid2009,mendoza2010}. Regions displaying qualitatively distinct dynamics will frequently contain trajectories with distinct arclengths and a large variation of the arclength indicate the presence of separatrices consisting of invariant manifolds \cite{mancho2013lagrangian}.</p>
<p>Lagrangian descriptors have advantages in comparison with other methodologies for the exploration of phase space structures. A notable advantage is that they are straightforward to implement.
Since its proposal as a nonlinear dynamics tool to explore phase space, this technique has found a myriad of applications in different scientific areas. For instance, it has been used in oceanography to plan transoceanic autonomous underwater vehicle missions by taking advantage of the underlying dynamical structure of ocean currents \cite{ramos2018}. Also, it has been shown to provide relevant information for the effective management of marine oil spills \cite{gg2016}. LDs have been used to analyze the structure of the Stratospheric Polar Vortex and its relation to sudden stratospheric warmings and also to ozone hole formation \cite{alvaro1,alvaro2,curbelo2019a,curbelo2019b}. In all these problems, the vector field defining the dynamical system is a discrete spatio-temporal dataset obtained from the numerical simulation of geophysical models. Recently, this tool has also received recognition in the field of chemistry, for instance in transition state theory \cite{craven2015lagrangian,craven2016deconstructing,craven2017lagrangian,revuelta2019unveiling}, where the computation of chemical reaction rates relies on the know-ledge of the phase space structures. These high-dimensional structures characterizing reaction dynamics are typically related to Normally Hyperbolic Invariant Manifolds (NHIMs) and their stable and unstable manifolds that occur in Hamiltonian systems. Other applications of LDs to chemical problems include the analysis of isomerization reactions \cite{naik2020,GG2020b}, roaming \cite{krajnak2019,gonzalez2020}, the study of the influence of bifurcations on the manifolds that control chemical reactions \cite{GG2020a}, and also the explanation of the dynamical matching mechanism in terms of the existence of heteroclinic connections in a Hamiltonian system defined by Caldera-type potential energy surfaces \cite{katsanikas2020a}.</p>
<div class="section" id="lagrangian-descriptors-versus-poincar-e-maps">
<h3>Lagrangian Descriptors versus Poincar’e Maps<a class="headerlink" href="#lagrangian-descriptors-versus-poincar-e-maps" title="Permalink to this headline">¶</a></h3>
<p>Poincar’e maps have been a standard and traditional technique for understanding the global phase space structure of dynamical systems. However,  Lagrangian descriptors offer substantial advantages over Poincar’e maps. We will describe these advantages in the context of the most common settings in which they are applied. However, we note that Lagrangian descriptors can be applied in exactly the same way to both Hamiltonian and non-Hamiltonian vector fields. In keeping with the spirit of this book, we will frame our discussion and description in the Hamiltonian setting.</p>
</div>
<div class="section" id="autonomous-hamiltonian-vector-fields">
<h3>Autonomous Hamiltonian vector fields<a class="headerlink" href="#autonomous-hamiltonian-vector-fields" title="Permalink to this headline">¶</a></h3>
<p>The consideration of the dimension of different geometric objects is crucial to understanding the advantages of Lagrangian descriptors over Poincar’e maps. Therefore we will first consider the “simplest” situation in which these arise — the autonomous Hamiltonian systems with two degrees of freedom.</p>
<p>A two degree-of-freedom Hamiltonian system is described by a four dimensional phase space described by coordinates <span class="math notranslate nohighlight">\((q_1, q_2, p_1, p_2)\)</span>. Moreover, we have seen in  Section REF that trajectories are restricted to a three dimensional energy surface (“energy conservation in autonomous Hamiltonian systems”). We choose a two dimensional surface within the energy surface that is transverse to the Hamiltonian vector field. This means that at no point on the two dimensional surface is the Hamiltonian vector field tangent  to the surface and that at every point on the surface the Hamiltonian vector field has the same directional sense (this is defined more precisely in REF). This two dimensional surface is referred to as a  surface of section (SOS) or a Poincar’e section, and it is the domain of the Poincar’e map. The image of a point under the Poincar’e map is the point on the trajectory, starting from that point, that first returns to the surface (and this leads to the fact that the Poincar’e map is sometimes referred to as a “first return map”).</p>
<p>The practical implementation of this procedure gives rise to several questions. Given a specific two degree-of-freedom Hamiltonian system can we find a two dimensional surface in the three dimensional energy surface having the property that it is transverse to the Hamiltonian vector field and “most” trajectories with initial conditions on the surface return to the surface? In general, the answer is “no” (unless we have some useful a priori knowledge of the phase space structure of the system). The advantage of the method of Lagrangian descriptors is that none of these features are required for its implementation, and it gives essentially the same information as Poincar’e maps.</p>
<p>However, the real advantage comes in considering higher dimensions, e.g autonomous Hamiltonian systems with more than two degrees-of-freedom. For definiteness, we will consider a three degree-of-freedom autonomous Hamiltonian system. In this case the phase space is six dimensional and  the energy surface is five dimensional. A cross section to the energy surface, in the sense described above, would be four dimensional (if an appropriate cross-section could be found). Solely on dimensionality considerations, we can see the difficulty. Choosing “enough” initial conditions on this four dimensional surface so that we can determine the phase space structures that are mapped out by the points that return to the cross-section is “non-trivial” (to say the least), and the situation only gets more difficult when we go to more than three degrees-of-freedom. One might imagine that you could start by considering lower dimensional subsets of the cross section. However, the probability that a trajectory would return to a lower dimensional subset is zero. Examples where Lagrangian descriptors have been used to analyse phase space structures in two and three degree-of-freedom Hamiltonian systems with this approach are given in \cite{demian2017,naik2019a,naik2019b,GG2019}.</p>
<p>Lagrangian descriptors avoid all of these difficulties. In particular, they can be computed on any subset of the phase space since there is no requirement for trajectories to return to that subset. Since phase space structure is encoded in the initial conditions (not the final state) of  trajectories a dense grid of initial conditions can be placed on any subset of the phase space and a “Lagrangian descriptor field” can be computed for that subset with high resolution and accuracy. Such computations are generally not possible using the Poincar’e map approach.</p>
</div>
<div class="section" id="nonautonomous-hamiltonian-vector-fields">
<h3>Nonautonomous Hamiltonian vector fields<a class="headerlink" href="#nonautonomous-hamiltonian-vector-fields" title="Permalink to this headline">¶</a></h3>
<p>Nonautonomous vector fields are fundamentally different than autonomous vector fields, and even more so for Hamiltonian vector fields. For example, one degree-of-freedom autonomous Hamiltonian vector fields are integrable. One degree-of-freedom autonomous Hamiltonian vector fields may exhibit chaos. Regardless of the dimension, a very significant difference is that energy is not conserved for nonautonomous Hamiltonian vector fields. Nevertheless, Lagrangian descriptors can be applied in exactly the same way as for autonomous Hamiltonian vector fields, <em>regardless of the nature of the time dependence. We add this last remark since the concept of Poincare maps  is not applicable unless the time dependence is periodic</em></p>
</div>
</div>
<div class="section" id="formulations-for-lagrangian-descriptors">
<h2>Formulations for Lagrangian Descriptors<a class="headerlink" href="#formulations-for-lagrangian-descriptors" title="Permalink to this headline">¶</a></h2>
<div class="section" id="the-arclength-definition">
<h3>The Arclength Definition<a class="headerlink" href="#the-arclength-definition" title="Permalink to this headline">¶</a></h3>
<p>In order to build some intuition on how the method works and understand its very simple and straightforward implementation, we start with the arclength definition mentioned in the previous section. This version of LDs is also known in the literature as function <span class="math notranslate nohighlight">\(M\)</span>. Consider any region of the phase space where one would like to reveal structures at time <span class="math notranslate nohighlight">\(t = t_0\)</span>, and create a uniformly-spaced grid of ICs <span class="math notranslate nohighlight">\(\mathbf{x}_0 = \mathbf{x}(t_0)\)</span> on it. Select a fixed integration time <span class="math notranslate nohighlight">\(\tau\)</span> that will be used to evolve all the trajectories generated from these ICs forward and backward in time for the time intervals <span class="math notranslate nohighlight">\([t_0,t_0+\tau]\)</span> and <span class="math notranslate nohighlight">\([t_0-\tau,t_0]\)</span> respectively. This covers a temporal range of <span class="math notranslate nohighlight">\(2\tau\)</span> centered at <span class="math notranslate nohighlight">\(t = t_0\)</span>, marking the time at which we want to take a snapshot of the underlying structures in phase space. The arclength of a trajectory in forward time can be easily calculated by solving he integral:</p>
<div class="math notranslate nohighlight">
\[{
\mathcal{L}^{f}(\mathbf{x}_{0},t_0,\tau) = \int^{t_0+\tau}_{t_0} ||\dot{\mathbf{x}}|| \; dt \;,
\label{eq:M_function_fw}
}\]</div>
<p>where
<span class="math notranslate nohighlight">\(\dot{\mathbf{x}} = \mathbf{f}(\mathbf{x}(t;\mathbf{x}_0),t)\)</span> and
<span class="math notranslate nohighlight">\(||\cdot||\)</span> is the Euclidean norm applied to the vector field defining the dynamical system in Eq. \eqref{eq:gtp_dynSys}. Similarly, one can define the arclength when the trajectory evolves in backward time as:</p>
<div class="math notranslate nohighlight">
\[{
\mathcal{L}^{b}(\mathbf{x}_{0},t_0,\tau) = \int^{t_0}_{t_0-\tau} ||\dot{\mathbf{x}}|| \; dt \;,
\label{eq:M_function_bw}
}\]</div>
<p>It is common practice to combine these two quantities into one scalar value so that:</p>
<div class="math notranslate nohighlight">
\[{
\mathcal{L}(\mathbf{x}_{0},t_0,\tau) = \mathcal{L}^{b}(\mathbf{x}_{0},t_0,\tau) + \mathcal{L}^{f}(\mathbf{x}_{0},t_0,\tau) \;,
\label{eq:M_function}
}\]</div>
<p>and in this way the scalar field provided by the method will simultaneously reveal the location of the stable and unstable manifolds in the same picture. However, if one only considers the output obtained from the forward or backward contributions, we can separately depict the stable and unstable manifolds respectively.</p>
<p>We illustrate the logic behind the capabilities of this technique to display the stable and unstable manifolds of hyperbolic points with a very simple example, the one degree-of-freedom (DoF) linear Hamiltonian saddle system given by:</p>
<div class="math notranslate nohighlight">
\[\begin{split}{
H(q,p) = \dfrac{1}{2} \left(p^2 - q^2\right)  \quad \Leftrightarrow \quad 
\begin{cases}
\dot{q} = \dfrac{\partial H}{\partial p} = p \\[.4cm]
\dot{p} = -\dfrac{\partial H}{\partial q} = q
\end{cases}
\label{eq:1dof_saddle}
}\end{split}\]</div>
<div class="figure align-default" id="d-saddle">
<img alt="../_images/1d_saddle_ld.png" src="../_images/1d_saddle_ld.png" />
<p class="caption"><span class="caption-number">Fig. 24 </span><span class="caption-text">Forward \eqref{eq:M_function_bw}, backward \eqref{eq:M_function_fw} and combined \eqref{eq:M_function} Lagrangian descriptors for system \eqref{eq:1dof_saddle} respectively.</span><a class="headerlink" href="#d-saddle" title="Permalink to this image">¶</a></p>
</div>
<p>We know that this dynamical system has a hyperbolic equilibrium point at the origin and that its stable and unstable invariant manifolds correspond to the lines <span class="math notranslate nohighlight">\(p = \pm q\)</span> respectively (refer to hyperbolic section). Outside of these lines, the trajectories are hyperbolas. What happens when we apply LDs to this system? Why does the method pick up the manifolds? Notice first that in Fig. \ref{fig:1d_saddle} the value attained by LDs at the origin is zero, because it is an equilibrium point and hence it is not moving. Therefore, the arclength of its trajectory is zero. Next, let’s consider the forward time evolution term of LDs, that is, <span class="math notranslate nohighlight">\(\mathcal{L}^f\)</span>. Take two neighboring ICs, one lying on the line that corresponds to the stable manifold and another slightly off it. If we integrate them for a time <span class="math notranslate nohighlight">\(\tau\)</span>, the initial condition that is on the manifold converges to the origin, while the other initial condition follows the arc of a hyperbola. If <span class="math notranslate nohighlight">\(\tau\)</span> is small, both segments of trajectory are comparable in length, so that the value obtained from LDs for both ICs is almost equal. However, if we integrate the system for a larger <span class="math notranslate nohighlight">\(\tau\)</span>, the arclengths of the two trajectories become very different, because one converges while the other one diverges. Therefore, we can clearly see  in Fig. \ref{fig:1d_saddle} that the LD values vary significantly near the stable manifold in comparison to those elsewhere. Moreover, if we consider a curve of initial conditions that crosses transversely the stable manifold, the LD value along it attains a minimum on the manifold. Notice also that by the same argument we gave above, but constructing the backward time evolution term of LDs, <span class="math notranslate nohighlight">\(\mathcal{L}^b\)</span>, we can arrive to the conclusion that backward integration of initial conditions will highlight the unstable manifold of the hyperbolic equilibrium point at the origin. It is important to remark here that, although we have used above the simple linear saddle system as an example to illustrate how the method recovers phase space structure, this argument also applies to a nonlinear system with an hyperbolic point, whose stable and unstable manifolds are convoluted curves.</p>
<p>The sharp transitions obtained for the LD values across the stable and unstable manifolds, which imply large values of its gradient in the vicinity of them, are known in the literature as “singular features”. These features present in the LD scalar field are very easy to visualize and detect when plotting the output provided by the method. We will see shortly that there exists a rigorous mathematical connection between the “singular features” displayed by the LD output and the stable and unstable manifolds of hyperbolic points. This result was first proved in \cite{lopesino2017} for two-dimensional flows, it was extended to 3D dynamical systems in \cite{gg2018}, and it has also been recently established for the stable and unstable manifolds of normally hyperbolic invariant manifolds in Hamiltonian systems with two or more degrees of freedom in \cite{demian2017,naik2019a}. In fact, the derivation of this relationship relies on an alternative definition for LDs, where the positive scalar function accumulated along the trajectories of the system is the <span class="math notranslate nohighlight">\(p\)</span>-norm of the vector field that determines the flow. Considering this approach, the LD scalar field becomes now non-differentiable at the phase space points that belong to a stable or unstable manifold, and consequently the gradient at these locations is unbounded. This property is crucial in many ways, since it allows us to easily recover the location of the stable and unstable manifolds in the LD plot as if they were the edges of objects that appear in a digital photograph.</p>
<p>One key aspect that needs to be accounted for when setting up LDs for revealing the invariant manifolds in phase space, is the crucial role that the integration time <span class="math notranslate nohighlight">\(\tau\)</span> plays in the definition of the method itself. It is very important to appreciate this point, since <span class="math notranslate nohighlight">\(\tau\)</span> is the parameter responsible for controlling the complexity and intricate geometry of the phase space structures revealed in the scalar field displayed from the LD computation. A natural consequence of increasing the value for <span class="math notranslate nohighlight">\(\tau\)</span> is that richer details of the underlying structures are unveiled, since this implies that we are incorporating more information about the past and future dynamical history of trajectories in the computation of LDs. This means that <span class="math notranslate nohighlight">\(\tau\)</span> in some sense is intimately related to the time scales of the dynamical phenomena that occur in the model under consideration. This connection makes the integration time a problem-dependent parameter, and hence, there is no general “golden rule” for selecting its value for exploring phase space. Consequently, it is usually selected from the dynamical information obtained by performing beforehand several numerical experiments, and one needs to bear in mind the compromise that exists between the complexity of the structures revealed by the method to explain a certain dynamical mechanism, and the interpretation of the intricate manifolds displayed in the LD scalar output.</p>
<p>To finish this part on the arclength definition of LDs we show that the method is also capable of revealing other invariant sets in phase space such as KAM tori, by means of studying the convergence of the time averages of LDs. We illustrate this property with the 1 DoF linear Hamiltonian with a center equilibrium at the origin:</p>
<p>\begin{equation}
H(q,p) = \dfrac{\omega}{2} \left(p^2 + q^2\right) \quad \Leftrightarrow \quad
\begin{cases}
\dot{q} = \dfrac{\partial H}{\partial p} = \omega , p \[.4cm]
\dot{p} = -\dfrac{\partial H}{\partial q} = -\omega , q
\end{cases}
\end{equation}</p>
<p>From the definition of the Hamiltonian we can see that the solutions to this system form a family of concentric circles about the origin with radius <span class="math notranslate nohighlight">\(R = \sqrt{2H/\omega}\)</span>. Moreover, each of this circles encloses an area of <span class="math notranslate nohighlight">\(A(H) = 2\pi H / \omega\)</span>. Using the definition of the Hamiltonian and the information provided by Hamilton’s equations of motion we can easily evaluate the arclength LD for this system:</p>
<p>\begin{equation}
\mathcal{L}(q_0,p_0,\tau) = \int^{\tau}<em>{-\tau} \sqrt{\left(\dot{q}\right)^2 + \left(\dot{p}\right)^2} ; dt = \omega \int^{\tau}</em>{-\tau} \sqrt{q^2 + p^2} ; dt = 2 \tau \sqrt{2 \omega H_0}
\end{equation}</p>
<p>where the initial condition <span class="math notranslate nohighlight">\((q_0,p_0)\)</span> has energy <span class="math notranslate nohighlight">\(H = H_0\)</span> and therefore it lies on a circular trajectory with radius <span class="math notranslate nohighlight">\(\sqrt{2H_0/\omega}\)</span>. Hence, in this case all trajectories constructed from initial conditions on that circle share the same LD value. Moreover, if we consider the convergence of the time average of LD, this yields:</p>
<p>\begin{equation}
\lim_{\tau \to \infty} \langle , \mathcal{L}(\tau)  , \rangle = \dfrac{1}{2\tau} \int^{\tau}_{-\tau} \sqrt{\left(\dot{q}\right)^2 + \left(\dot{p}\right)^2} ; dt = \sqrt{2 \omega H_0} = \omega \sqrt{\frac{A}{\pi}}
\end{equation}</p>
<p>which proves that the phase space points for which the time average of LDs converges to the same value are part of the same invariant set. For more details about the relationship between the convergence of time averages of LDs and KAM tori, see \cite{lopesino2017,naik2019a}.</p>
</div>
<div class="section" id="the-p-norm-definition">
<h3>The <span class="math notranslate nohighlight">\(p\)</span>-norm Definition<a class="headerlink" href="#the-p-norm-definition" title="Permalink to this headline">¶</a></h3>
<p>Besides the arclength definition of Lagrangian descriptors introduced in the previous subsection, there are many other versions used throughout the literature. An alternative definition of LDs, which is inspired by the <span class="math notranslate nohighlight">\(p\)</span>-norm of the vector field describing the dynamical system. We remark that we use the expression for <span class="math notranslate nohighlight">\(p\in(0,1]\)</span>, while the <span class="math notranslate nohighlight">\(p\)</span>-norm is only a norm for <span class="math notranslate nohighlight">\(p\geq 1\)</span>. For the sake of consistency with literature we retain the name <span class="math notranslate nohighlight">\(p\)</span>-norm even for <span class="math notranslate nohighlight">\(p&lt;1\)</span>. The LD is defined as:</p>
<div class="math notranslate nohighlight">
\[{
\mathcal{L}_p(\mathbf{x}_{0},t_0,\tau) = \int^{t_0+\tau}_{t_0-\tau} \, \sum_{k=1}^{n}   \vert f_{k}(\mathbf{x}(t;\mathbf{x}_0),t) \vert^p \; dt  \;, \quad p \in (0,1]
\label{eq:Mp_function}
}\]</div>
<p>where <span class="math notranslate nohighlight">\(f_{k}\)</span> is the <span class="math notranslate nohighlight">\(k\)</span>-th component of the vector field in Eq. \eqref{eq:gtp_dynSys}. Typically, the value used for the parameter <span class="math notranslate nohighlight">\(p\)</span> in this version of the method is <span class="math notranslate nohighlight">\(p = 1/2\)</span>. Recall that all the variants of LDs can be split into its forward and backward time integration components in order to detect the stable and unstable manifolds separately. Hence, we can write:</p>
<div class="math notranslate nohighlight">
\[{
\mathcal{L}_p(\mathbf{x}_{0},t_0,\tau) = \mathcal{L}^{b}_p(\mathbf{x}_{0},t_0,\tau) + \mathcal{L}^{f}_p(\mathbf{x}_{0},t_0,\tau)
}\]</div>
<p>where we have that:</p>
<div class="math notranslate nohighlight">
\[\begin{split}{
\begin{split}
\mathcal{L}_p^{b}(\mathbf{x}_{0},t_0,\tau) &amp; = \int^{t_0}_{t_0-\tau}  \sum_{k=1}^{n} |f_{k}(\mathbf{x}(t;\mathbf{x}_0),t)|^p \; dt \\[.2cm]
\mathcal{L}_p^{f}(\mathbf{x}_{0},t_0,\tau) &amp; = \int^{t_0+\tau}_{t_0} \sum_{k=1}^{n} |f_{k}(\mathbf{x}(t;\mathbf{x}_0),t)|^p \; dt
\end{split}
}\end{split}\]</div>
<p>Although this alternative definition of LDs does not have such an intuitive physical interpretation as that of arclength, it has been shown to provide many advantages. For example, it allows for a rigorous analysis of the notion of “singular features” and to establish the mathematical connection of this notion to stable and unstable invariant manifolds in phase space. Another important aspect of the <span class="math notranslate nohighlight">\(p\)</span>-norm of LDs is that, since in the definition all the vector field components contribute separately, one can naturally decompose the LD in a way that allows to isolate individual degrees of freedom. This was used in \cite {demian2017,naik2019a} to show that the method can be used to successfully detect NHIMs and their stable and unstable manifolds in Hamiltonian systems. Using the <span class="math notranslate nohighlight">\(p-\)</span>norm definition, it has been shown that the points on the LD contour map with non-differentiability identifies the invariant manifolds’ intersections with the section on which the LD is computed, for specific systems ~\cite{lopesino2017,demian2017,naik2019a}. In this context, where a fixed integration time is used, it has also been shown that the LD scalar field attains a minimum value at the locations of the stable and unstable manifolds, and hence:</p>
<div class="math notranslate nohighlight">
\[{
\mathcal{W}^u(\mathbf{x}_{0},t_0) = \textrm{argmin } \mathcal{L}_p^{b}(\mathbf{x}_{0},t_0,\tau) \quad,\quad \mathcal{W}^s(\mathbf{x}_{0},t_0) = \textrm{argmin } \mathcal{L}_p^{f}(\mathbf{x}_{0},t_0,\tau) \;,
\label{eq:min_LD_manifolds}
}\]</div>
<p>where <span class="math notranslate nohighlight">\(\mathcal{W}^u\)</span> and <span class="math notranslate nohighlight">\(\mathcal{W}^s\)</span> are, respectively, the unstable and stable manifolds calculated at time <span class="math notranslate nohighlight">\(t_0\)</span> and <span class="math notranslate nohighlight">\(\textrm{argmin}(\cdot)\)</span> denotes the phase space coordinates <span class="math notranslate nohighlight">\(\mathbf{x}_0\)</span> that minimize the corresponding function. In addition, NHIMs at time <span class="math notranslate nohighlight">\(t_0\)</span> can be calculated as the intersection of the stable and unstable manifolds:</p>
<div class="math notranslate nohighlight">
\[{
\mathcal{N}(\mathbf{x}_{0},t_0) = \mathcal{W}^u(\mathbf{x}_{0},t_0) \cap \mathcal{W}^s(\mathbf{x}_{0},t_0) = \textrm{argmin } \mathcal{L}_p(\mathbf{x}_{0},t_0,\tau)
\label{eq:min_NHIM_LD}
}\]</div>
<p>As we have pointed out, the location of the stable and unstable manifolds on the slice can be obtained by extracting them from the ridges of the gradient field, <span class="math notranslate nohighlight">\(\Vert \nabla \mathcal{L}^{f}_p \Vert\)</span> or <span class="math notranslate nohighlight">\(\Vert \nabla \mathcal{L}^{b}_p \Vert\)</span>, respectively, since manifolds are located at points where the the forward and backward components of the function <span class="math notranslate nohighlight">\(\mathcal{L}_p\)</span> are non-differentiable. Once the manifolds are known one can compute their intersection by means of a root search algorithm. In specific examples we have been able to extract NHIMs from the intersections. An alternative method to recover the manifolds and their associated NHIM is by minimizing the functions  <span class="math notranslate nohighlight">\(\mathcal{L}^{f}_p\)</span> and <span class="math notranslate nohighlight">\(\mathcal{L}^{b}_p\)</span> using a search optimization algorithm. This second procedure and some interesting variations are described in \cite{feldmaier2019}.</p>
<p>We finish the description of the <span class="math notranslate nohighlight">\(p\)</span>-norm version of LDs by showing that this definition recovers the stable and unstable manifolds of hyperbolic equilibria at phase space points where the scalar field is non-differentiable. We demonstrate this statement for the 1 DoF linear Hamiltonian introduced in Eq. \eqref{eq:Mp_function} that has a saddle equilibrium point at the origin. The general solution to this dynamical system can be written as:</p>
<p>\begin{equation}
q(t) = \dfrac{1}{2} \left(A e^{t} + B e^{-t}\right) \quad,\quad p(t) = \dfrac{1}{2} \left(A e^{t} - B e^{-t}\right)
\end{equation}</p>
<p>where <span class="math notranslate nohighlight">\(\mathbf{x}_0 = (q_0,p_0)\)</span> is the initial condition and <span class="math notranslate nohighlight">\(A = q_0 + p_0\)</span> and <span class="math notranslate nohighlight">\(B = q_0 - p_0\)</span>. If we compute the forward plus backward contribution of the LD function, we get that for <span class="math notranslate nohighlight">\(\tau\)</span> sufficiently large the scalar field behaves asymptotically as:</p>
<p>\begin{equation}
\mathcal{L}_{p}\left(\mathbf{x}_0,\tau\right) \sim \left(|A|^{p} + |B|^{p}\right)  e^{p \tau}
\label{M_hyp_asymp}
\end{equation}</p>
<p>Therefore, this shows that the scalar field grows exponentially with <span class="math notranslate nohighlight">\(\tau\)</span> and also that the leading order singularities in <span class="math notranslate nohighlight">\(\mathcal{L}_{p}\)</span> occur when <span class="math notranslate nohighlight">\(|A| = 0\)</span>, that is, when <span class="math notranslate nohighlight">\(p_0 = -  q_0\)</span>, which corresponds to initial conditions on the stable manifold of the system, or in the case where <span class="math notranslate nohighlight">\(|B| = 0\)</span>, that is, <span class="math notranslate nohighlight">\(p_0 = q_0\)</span>, representing initial conditions on the unstable manifold. Moreover, <span class="math notranslate nohighlight">\(\mathcal{L}_{p}\)</span> is non-differentiable at the hyperbolic point at the origin, since it is given by the intersection of the stable and unstable invariant manifolds. For more details on how this computation is carried out, we refer the reader to \cite{lopesino2017,demian2017,naik2019a}. Notice also that this argument is easily applicable for Hamiltonian systems with <span class="math notranslate nohighlight">\(N \geq 2\)</span> DoF in order to prove that LDs detects normally hyperbolic invariant manifolds (unstable periodic orbits for 2 DOF systems) and their stable and unstable manifolds at points where the output of the <span class="math notranslate nohighlight">\(p\)</span>-norm LD is singular.</p>
</div>
<div class="section" id="lagrangian-descriptors-based-on-the-classical-action">
<h3>Lagrangian Descriptors Based on the Classical Action<a class="headerlink" href="#lagrangian-descriptors-based-on-the-classical-action" title="Permalink to this headline">¶</a></h3>
<p>\label{sec:LDaction}</p>
<p>In this section we discuss a formulation of Lagrangian descriptors that has a direct connection to classical Hamiltonian mechanics, namely the principle of least action. The principle of least action is treated in most advanced books on classical mechanics; see, for example, \cite{arnol2013mathematical, goldstein2002classical, landau2013mechanics}. An intuitive and  elementary discussion of the principle of least action is given by Richard Feynman in the following lecture \url{https://www.feynmanlectures.caltech.edu/II_19.html},</p>
<p>To begin, we note that the general form of Lagrangian descriptors are as follows:
\begin{equation}
\mathcal{L}(\text{initial condition}) = \int_{t_0 - \tau}^{t_0 + \tau} \text{PositiveFunction} , (\text{trajectory}) ; dt
\end{equation}
\noindent
The positivity of the integrand is often imposed via an absolute value. In our discussion below we show that this is not necessary for the action.</p>
<div class="section" id="one-degree-of-freedom-autonomous-hamiltonian-systems">
<h4>One Degree-of-Freedom Autonomous Hamiltonian Systems<a class="headerlink" href="#one-degree-of-freedom-autonomous-hamiltonian-systems" title="Permalink to this headline">¶</a></h4>
<p>We consider a Hamiltonian of the form:</p>
<p>\begin{equation}
H(q, p) = \frac{p^2}{2m} + V(q) ;, \quad (q,p) \in \mathbb{R}^2.
\end{equation}
The integrand for the action integral is the following:
\begin{equation}
p , dq ;,
\end{equation}Using the chain rule and the definition of momentum, the following calculations are straightforward:
\begin{eqnarray}
p , dq = p \frac{dq}{dt} dt = \frac{p^2}{m} dt ;.
\end{eqnarray}</p>
<p>The quantity <span class="math notranslate nohighlight">\(\frac{p^2}{m}\)</span> is twice the kinetic energy and is known as the {\em vis viva}. It is the integrand for the integral that defines Maupertuis principle, which is very closely related to the principle of least action. We can also write <span class="math notranslate nohighlight">\(p \, dq\)</span> slightly differently using Hamilton’s equations:</p>
<p>\begin{equation}
\dfrac{p^2}{m}= 2 (H - V(q) ),
\end{equation}
from which it follows that:
\begin{equation}
p , dq = \dfrac{p^2}{m} , dt = 2 (H-V(q)) , dt.
\end{equation}
Therefore, the positive quantities that appear multiplying the <span class="math notranslate nohighlight">\(dt\)</span> are candidates for the integrand of Lagrangian descriptors~\cite{montoya2020phase}.</p>
<p>\smallskip</p>
<p>We will illustrate next how the action-based LDs successfully detects the stable invariant manifold of the hyperbolic equilibrium point in system introduced in Eq. \eqref{eq:1dof_saddle}. We know that the solutions to this dynamical system are given by the expressions:
\begin{equation}
q(t) = q_0 \cosh(t) + p_0 \sinh(t) \quad,\quad p(t) = p_0 \cosh(t) + q_0 \sinh(t)
\end{equation}
where <span class="math notranslate nohighlight">\((q_0,p_0)\)</span> represents any initial condition. We know from (refer to hyperbolic section) that the stable invariant manifold is given by <span class="math notranslate nohighlight">\(q = -p\)</span>. We compute the forward LD:
\begin{equation}
\begin{split}
\mathcal{A}^{f}(q_0,p_0,\tau) &amp; = \int_{0}^{\tau} p , \dfrac{dq}{dt} , dt = \int_{0}^{\tau} p^2 , dt = \[.2cm]
&amp; = \dfrac{1}{2} \left(p_0^2 - q_0^2\right) \tau + \dfrac{1}{4}\left(q_0^2 + p_0^2\right) \sinh(2\tau) + \dfrac{1}{2} q_0 , p_0 \left(\cosh(2\tau) - 1\right)
\end{split}
\end{equation}
It is a simple exercise to check that <span class="math notranslate nohighlight">\(\mathcal{A}^{f}\)</span> attains a local minimum at the points:
\begin{equation}
q_0 = - \dfrac{\cosh(2\tau) - 1}{\sinh(2\tau) - 2 \tau} , p_0
\end{equation}
and notice now that if <span class="math notranslate nohighlight">\(\tau\)</span> is sufficiently large, this condition tends exponentially to the points on the stable manifold of the system, <span class="math notranslate nohighlight">\(q_0 = - p_0\)</span>. A similar argument, but considering the backward integration, yields the unstable manifold located at points on the line <span class="math notranslate nohighlight">\(q = p\)</span>.</p>
</div>
<div class="section" id="n-degree-of-freedom-autonomous-hamiltonian-systems">
<h4><span class="math notranslate nohighlight">\(n\)</span> Degree-of-Freedom Autonomous Hamiltonian Systems<a class="headerlink" href="#n-degree-of-freedom-autonomous-hamiltonian-systems" title="Permalink to this headline">¶</a></h4>
<p>The above calculations for one DoF are easily generalized to <span class="math notranslate nohighlight">\(n\)</span> degrees-of-freedom. We begin with a Hamiltonian of the form:
\begin{equation}
H(q_1, \ldots, q_n, p_1, \ldots, p_n) = \sum_{i=1}^n \dfrac{p_i^2}{2m_i} + V(q_1, \ldots, q_n) ;, \quad (q_1, \ldots, q_n, p_1, \ldots, p_n) \in \mathbb{R}^{2n}.
\end{equation}
The integrand for the action integral is the following:	
\begin{equation}
p_1dq_1 + \cdots + p_n dq_n \quad , \quad p_i\equiv m_i \frac{dq_i}{dt} ;, \quad i \in \lbrace 1,\ldots,n \rbrace
\end{equation}
As above, using the chain rule and the definition of the momentum, we get:
\begin{equation}
p_1dq_1 + \cdots + p_n dq_n = \sum_{i=1}^n p_i \frac{dq_i}{dt} dt = \sum_{i=1}^n  \dfrac{p_i^2}{m_i} dt
\end{equation}
where the quantity <span class="math notranslate nohighlight">\(\sum_{i=1}^n  \dfrac{p_i^2}{m_i}\)</span> is twice the kinetic energy and is the vis-viva in the <span class="math notranslate nohighlight">\(n\)</span> degree-of-freedom setting. We can write $p_1dq_1 + \cdots + p_n dq_n $ slightly differently using Hamilton’s equations,
\begin{equation}
\sum_{i=1}^n \frac{p_i ^2}{2m_i} =  2 (H - V(q_1, \ldots, q_n) )
\end{equation}
from which it follows that
\begin{equation}
p_1dq_1 + \cdots + p_n dq_n =  \sum_{i=1}^n \frac{p_i ^2}{2m_i} dt = 2 (H-V(q_1, \ldots, q_n)) dt
\end{equation}
In summary, we can use the vis-viva as the integrand for Lagrangian descriptors. It is very closely related to action as you can see above. Action based Lagrangian descriptors have been successfully used in RAFA’s paper (to be added later) FRANCISCO’s new paper~\cite{montoya2020phase}.</p>
</div>
</div>
</div>
<div class="section" id="variable-integration-time-lagrangian-descriptors">
<h2>Variable Integration Time Lagrangian Descriptors<a class="headerlink" href="#variable-integration-time-lagrangian-descriptors" title="Permalink to this headline">¶</a></h2>
<p>At this point, we would like to discuss the issues that might arise from the definitions of LDs provided in Eqs. \eqref{eq:M_function} and \eqref{eq:Mp_function} when they are applied to analyze the dynamics in open Hamiltonian systems, that is, those for which phase space dynamics occurs in unbounded energy hypersurfaces. Notice that in both definitions, all the initial conditions considered by the method are integrated forward and backward for the same time <span class="math notranslate nohighlight">\(\tau\)</span>. Recent studies have revealed  \cite{junginger2017chemical,naik2019b,GG2020a} issues with trajectories that escape to infinity in finite time or at an increasing rate. The trajectories that show this behavior will give NaN (not-a-number) values in the LD scalar field, hiding some regions of the phase space, and therefore obscuring the detection of invariant manifolds. In order to circumvent this problem we explain here the approach that has been recently adopted in the literature \cite{junginger2017chemical,naik2019b,GG2020a} known as variable integration time Lagrangian descriptors. In this methodology, LDs at any initial condition are calculated for a fixed initial integration time <span class="math notranslate nohighlight">\(\tau_0\)</span> or until the trajectory corresponding to that initial condition leaves a certain phase space region <span class="math notranslate nohighlight">\(\mathcal{R}\)</span> that we call the {\em interaction region}, whichever happens first. Therefore the total integration time depends on the initial conditions, that is <span class="math notranslate nohighlight">\(\tau(\mathbf{x}_0)\)</span>. In this variable-time formulation, given a fixed integration time <span class="math notranslate nohighlight">\(\tau_0 &gt; 0\)</span>, the <span class="math notranslate nohighlight">\(p\)</span>-norm definition of LDs with <span class="math notranslate nohighlight">\(p \in (0,1]\)</span> will take the form:</p>
<div class="math notranslate nohighlight">
\[{
\mathcal{L}_p(\mathbf{x}_{0},t_0,\tau_0) = \int^{t_0 + \tau^{+}_{\mathbf{x}_0}}_{t_0 - \tau^{-}_{\mathbf{x}_0}} \sum_{k=1}^{n} |f_{k}(\mathbf{x}(t;\mathbf{x}_0),t)|^p \; dt  = \mathcal{L}^{f}_p(\mathbf{x}_{0},t_0,\tau) + \mathcal{L}^{b}_p(\mathbf{x}_{0},t_0,\tau)
\label{eq:Mp_vt}
}\]</div>
<p>where the total integration time used for each initial condition is defined as:</p>
<div class="math notranslate nohighlight">
\[{
\tau^{\pm}_{\mathbf{x}_{0}}(\tau_0,\mathcal{R}) = \min \left\lbrace \tau_0 \, , \, |t^{\pm}| \right\rbrace \; ,
}\]</div>
<p>and <span class="math notranslate nohighlight">\(t^{+}\)</span>, <span class="math notranslate nohighlight">\(t^{-}\)</span> represent the times for which the trajectory leaves the interaction region <span class="math notranslate nohighlight">\(\mathcal{R}\)</span> in forward and backward time respectively.</p>
<p>It is important to highlight that the variable time integration LD has also the capability of capturing the locations of the stable and unstable manifolds present in the phase space slice used for the computation, and it will do so at points where the LD values vary significantly. Moreover, KAM tori will also be detected by the contour values of the time-averaged LD. Therefore, the variable integration time LDs provides us with a suitable methodology to study the phase space structures that characterize escaping dynamics in open Hamiltonians, since it avoids the issue of trajectories escaping to infinity very fast. It is important to remark here that this alternative approach for computing LDs can be adapted to other definitions of the method, where a different positive and bounded function is integrated along the trajectories of the dynamical system. For example, going back to the arclength definition of LDs, the variable  integration time strategy would yield the formulation:</p>
<div class="math notranslate nohighlight">
\[{
\mathcal{L}(\mathbf{x}_{0},t_0,\tau_0) = \int^{t_0 + \tau^{+}_{\mathbf{x}_0}}_{t_0 - \tau^{-}_{\mathbf{x}_0}} \Vert \mathbf{f}(\mathbf{x}(t;\mathbf{x}_0),t) \Vert \, dt
\label{eq:M_vt}
}\]</div>
</div>
<div class="section" id="examples">
<h2>Examples<a class="headerlink" href="#examples" title="Permalink to this headline">¶</a></h2>
<div class="section" id="the-duffing-oscillator">
<h3>The Duffing Oscillator<a class="headerlink" href="#the-duffing-oscillator" title="Permalink to this headline">¶</a></h3>
<p>In the next example, we illustrate how the arclength and the function <span class="math notranslate nohighlight">\(M\)</span> LDs capture the stable and unstable manifolds that determine the phase portrait of the forced and undamped Duffing oscillator. The Duffing equation arises when studying the motion of a particle on a line, i.e. a one DoF system, subjected to the influence of a symmetric double well potential and an external forcing. The second order ODE that describes this oscillator is given by:</p>
<p>\begin{equation}
\ddot{x} + x^3 - x = \varepsilon f(t)
\end{equation}
where <span class="math notranslate nohighlight">\(\varepsilon\)</span> represents the strength of the forcing term <span class="math notranslate nohighlight">\(f(t)\)</span>, and we choose for this example a sinusoidal force <span class="math notranslate nohighlight">\(f(t) = \sin(\omega t + \phi)\)</span>, where <span class="math notranslate nohighlight">\(\omega\)</span> the angular frequency and <span class="math notranslate nohighlight">\(\phi\)</span> the phase of the forcing. Reformulated using a Hamiltonian function <span class="math notranslate nohighlight">\(H\)</span>, this system can be written as:</p>
<p>\begin{equation}
H(x,y) = \dfrac{1}{2} y^2 + \dfrac{1}{4} x^4 - \dfrac{1}{2} x^2 - \varepsilon f(t) x \quad \Leftrightarrow \quad
\begin{cases}
\dot{x} = y \
\dot{y} = x - x^3 + \varepsilon f(t) \
\end{cases}
\end{equation}</p>
<p>In the autonomous case, i.e. <span class="math notranslate nohighlight">\(\varepsilon = 0\)</span>, the system has three equilibrium points: a saddle located at the origin and two diametrically opposed centers at the points <span class="math notranslate nohighlight">\((\pm 1,0)\)</span>. The stable and unstable manifolds that emerge from the saddle point form two homoclininc orbits in the form of a figure eight around the two center equilibria:</p>
<div class="math notranslate nohighlight">
\[{
\mathcal{W}^{s} = \mathcal{W}^{u} = \left\{(x,y) \in \mathbb{R}^2 \; \Big| \; 2y^2 + x^4 - 2x^2 = 0 \right\}
\label{eq:duff_homocMani}
}\]</div>
<p>We begin by computing LDs for the unforced Duffing system using <span class="math notranslate nohighlight">\(\tau = 2\)</span>. For this small integration time, the method highlights the saddle and center fixed points, since the arclength at those points is always zero. In this case the phase portrait looks blurry as shown in Fig. \ref{fig:duffing1_lds} A), and this is a consequence of trajectories not being sufficiently dynamically distinct by the end of the integration interval. If we increase the integration time to <span class="math notranslate nohighlight">\(\tau = 10\)</span>, we can see in Fig. \ref{fig:duffing1_lds} B) that the homoclinic connection formed by the stable and unstable manifolds of the saddle point at the origin becomes clearly visible. Moreover, observe that the manifolds are located at points where the scalar values taken by LDs change abruptly. This property is demonstrated in Fig. \ref{fig:duffing1_lds} C), where we have depicted the value of function <span class="math notranslate nohighlight">\(M\)</span> along the line <span class="math notranslate nohighlight">\(y = 0.5\)</span>. Notice that sharp changes in the scalar field of LDs at the manifolds are also related to local minima.</p>
<div class="figure align-default" id="id1">
<img alt="../_images/duffing_tau_2.png" src="../_images/duffing_tau_2.png" />
<p class="caption"><span class="caption-number">Fig. 25 </span><span class="caption-text">Phase portrait of the autonomous and undamped Duffing oscillator obtained by applying the arclength definition of LDs in Eq. \eqref{eq:M_function}. A) LDs with <span class="math notranslate nohighlight">\(\tau = 2\)</span></span><a class="headerlink" href="#id1" title="Permalink to this image">¶</a></p>
</div>
<div class="figure align-default" id="id2">
<img alt="../_images/duffing_tau_10.png" src="../_images/duffing_tau_10.png" />
<p class="caption"><span class="caption-number">Fig. 26 </span><span class="caption-text">Phase portrait of the autonomous and undamped Duffing oscillator obtained by applying the arclength definition of LDs in Eq. \eqref{eq:M_function}.  B) LDs with <span class="math notranslate nohighlight">\(\tau = 10\)</span></span><a class="headerlink" href="#id2" title="Permalink to this image">¶</a></p>
</div>
<div class="figure align-default" id="duffing1-lds">
<img alt="../_images/duffing_maniDetect.png" src="../_images/duffing_maniDetect.png" />
<p class="caption"><span class="caption-number">Fig. 27 </span><span class="caption-text">Phase portrait of the autonomous and undamped Duffing oscillator obtained by applying the arclength definition of LDs in Eq. \eqref{eq:M_function}. C) Value of LDs along the line <span class="math notranslate nohighlight">\(y = 0.5\)</span> depicted in panel B) illustrating how the method detects the stable and unstable manifolds at points where the scalar field changes abruptly.</span><a class="headerlink" href="#duffing1-lds" title="Permalink to this image">¶</a></p>
</div>
<p>We move on to compute LDs for the forced Duffing oscillator. In this situation, the vector field is time-dependent and thus the dynamical system is nonautonomous. The consequence is that the homoclinic connection breaks up and the stable and unstable manifolds intersect, forming an intricate tangle that gives rise to chaos. We illustrate this phenomenon by computing LDs with <span class="math notranslate nohighlight">\(\tau = 10\)</span> to reconstruct the phase portrait at the initial time <span class="math notranslate nohighlight">\(t_0 = 0\)</span>. For the forcing, we use a perturbation strength <span class="math notranslate nohighlight">\(\varepsilon = 0.1\)</span>, an angular frequency of <span class="math notranslate nohighlight">\(\omega = 1\)</span> and a phase <span class="math notranslate nohighlight">\(\phi = 0\)</span>. This result is shown in Fig. \ref{fig:duffing2_lds} C), and we also depict the forward <span class="math notranslate nohighlight">\((\mathcal{L}^f)\)</span> and backward <span class="math notranslate nohighlight">\((\mathcal{L}^b)\)</span> contributions of LDs in Fig. \ref{fig:duffing2_lds} A) and B) respectively, demonstrating that the method can be used to recover the stable and unstable manifolds separately. Furthermore, by taking the value of LDs along the line <span class="math notranslate nohighlight">\(y = 0.5\)</span>, the location of the invariant manifolds are highlighted at points corresponding to sharp changes (and local minima) in the scalar field values of LDs.</p>
<div class="figure align-default" id="id3">
<img alt="../_images/duffing_stbl_tau_10_pert_01.png" src="../_images/duffing_stbl_tau_10_pert_01.png" />
<p class="caption"><span class="caption-number">Fig. 28 </span><span class="caption-text">Phase portrait of the nonautonomous and undamped Duffing oscillator obtained at time <span class="math notranslate nohighlight">\(t = 0\)</span> by applying the arclength definition of LDs in Eq. \eqref{eq:M_function} with an integration time <span class="math notranslate nohighlight">\(\tau = 10\)</span>. A) Forward LDs detect stable manifolds</span><a class="headerlink" href="#id3" title="Permalink to this image">¶</a></p>
</div>
<div class="figure align-default" id="id4">
<img alt="../_images/duffing_unstbl_tau_10_pert_01.png" src="../_images/duffing_unstbl_tau_10_pert_01.png" />
<p class="caption"><span class="caption-number">Fig. 29 </span><span class="caption-text">Phase portrait of the nonautonomous and undamped Duffing oscillator obtained at time <span class="math notranslate nohighlight">\(t = 0\)</span> by applying the arclength definition of LDs in Eq. \eqref{eq:M_function} with an integration time <span class="math notranslate nohighlight">\(\tau = 10\)</span>. B) Backward LDs highlight unstable manifolds of the system</span><a class="headerlink" href="#id4" title="Permalink to this image">¶</a></p>
</div>
<div class="figure align-default" id="id5">
<img alt="../_images/duffing_tau_10_pert_01.png" src="../_images/duffing_tau_10_pert_01.png" />
<p class="caption"><span class="caption-number">Fig. 30 </span><span class="caption-text">Phase portrait of the nonautonomous and undamped Duffing oscillator obtained at time <span class="math notranslate nohighlight">\(t = 0\)</span> by applying the arclength definition of LDs in Eq. \eqref{eq:M_function} with an integration time <span class="math notranslate nohighlight">\(\tau = 10\)</span>. C) Total LDs (forward <span class="math notranslate nohighlight">\(+\)</span> backward) showing that all invariant manifolds are recovered simultaneously.</span><a class="headerlink" href="#id5" title="Permalink to this image">¶</a></p>
</div>
<div class="figure align-default" id="duffing2-lds">
<img alt="../_images/duffing_maniDetect_pert_01.png" src="../_images/duffing_maniDetect_pert_01.png" />
<p class="caption"><span class="caption-number">Fig. 31 </span><span class="caption-text">Phase portrait of the nonautonomous and undamped Duffing oscillator obtained at time <span class="math notranslate nohighlight">\(t = 0\)</span> by applying the arclength definition of LDs in Eq. \eqref{eq:M_function} with an integration time <span class="math notranslate nohighlight">\(\tau = 10\)</span>. D) Value taken by LDs along the line <span class="math notranslate nohighlight">\(y = 0.5\)</span> in panel C) to illustrate how the method detects the stable and unstable manifolds at points where the scalar field changes abruptly.</span><a class="headerlink" href="#duffing2-lds" title="Permalink to this image">¶</a></p>
</div>
</div>
<div class="section" id="the-linear-hamiltonian-saddle-with-2-dof">
<h3>The linear Hamiltonian saddle with 2 DoF<a class="headerlink" href="#the-linear-hamiltonian-saddle-with-2-dof" title="Permalink to this headline">¶</a></h3>
<p>Consider the two DoF system given by the linear quadratic Hamiltonian associated to an index-1 saddle at the origin. This Hamiltonian and the equations of motion are given by the expressions:</p>
<div class="math notranslate nohighlight">
\[\begin{split}{
H(x,y,p_x,p_y) = \dfrac{\lambda}{2}\left(p_x^2 - x^2\right) + \dfrac{\omega}{2} \left(p_y^2 + y^2 \right) \quad,\quad \begin{cases}
\dot{x} = \lambda \, p_x \\
\dot{p}_{x} = \lambda \, x \\
\dot{y} = \omega \, p_y \\
\dot{p}_{y} = -\omega \, y 
\end{cases}
\label{eq:index1_Ham}
}\end{split}\]</div>
<p>For this dynamical system we compute the <span class="math notranslate nohighlight">\(p\)</span>-norm LDs in the saddle space <span class="math notranslate nohighlight">\(x-p_x\)</span> of the linear Hamiltonian given in Eq. \eqref{eq:index1_Ham} using <span class="math notranslate nohighlight">\(p = 1/2\)</span> and for an integration time <span class="math notranslate nohighlight">\(\tau = 10\)</span>. In Fig. \ref{fig:index1_lds} we illustrate how the method detects the stable (red) and unstable (blue) manifolds of the unstable periodic orbit at the origin, and these manifolds can be directly extracted from the ridges of the scalar field <span class="math notranslate nohighlight">\(||\nabla \mathcal{L}^{f/b}_p||\)</span> respectively. Moreover, we show in Fig. \ref{fig:index1_lds} C) that the LD scalar field is non-differentiable at the manifolds and also attains a local minimum on them, and we do so by looking at the values taken by <span class="math notranslate nohighlight">\(M_p\)</span> along the line <span class="math notranslate nohighlight">\(p_x = 1/2\)</span>.</p>
<div class="figure align-default" id="id6">
<img alt="../_images/LD_p_05_Saddle_tau_10.png" src="../_images/LD_p_05_Saddle_tau_10.png" />
<p class="caption"><span class="caption-number">Fig. 32 </span><span class="caption-text">Phase portrait in the saddle space of the linear Hamiltonian given in Eq. \eqref{eq:index1_Ham}. A) Application of the <span class="math notranslate nohighlight">\(p\)</span>-norm definition of LDs in Eq. \eqref{eq:Mp_function} using <span class="math notranslate nohighlight">\(p = 1/2\)</span> with <span class="math notranslate nohighlight">\(\tau = 10\)</span>.</span><a class="headerlink" href="#id6" title="Permalink to this image">¶</a></p>
</div>
<div class="figure align-default" id="id7">
<img alt="../_images/manifolds_Saddle_tau_10.png" src="../_images/manifolds_Saddle_tau_10.png" />
<p class="caption"><span class="caption-number">Fig. 33 </span><span class="caption-text">B) Stable (blue) and unstable (red) invariant manifolds of the unstable periodic orbit at the origin extracted from the gradient of the <span class="math notranslate nohighlight">\(M_p\)</span> function.</span><a class="headerlink" href="#id7" title="Permalink to this image">¶</a></p>
</div>
<div class="figure align-default" id="index1-lds">
<img alt="../_images/detectMani_Saddle_tau_10.png" src="../_images/detectMani_Saddle_tau_10.png" />
<p class="caption"><span class="caption-number">Fig. 34 </span><span class="caption-text">C) Value of LDs along the line <span class="math notranslate nohighlight">\(p_x = 0.5\)</span> depicted in panel A) to illustrate how the method detects the stable and unstable manifolds at points where the scalar field is singular or non-differentiable and attains a local minimum.</span><a class="headerlink" href="#index1-lds" title="Permalink to this image">¶</a></p>
</div>
</div>
<div class="section" id="the-cubic-potential">
<h3>The Cubic Potential<a class="headerlink" href="#the-cubic-potential" title="Permalink to this headline">¶</a></h3>
<p>In order to illustrate the issues encountered by the fixed integration time LDs and how the variable integration approach resolves them, we apply the method to a basic one degree-of-freedom Hamiltonian known as the ``fish potential’’, which is given by the formula:
\begin{equation}
H = \dfrac{1}{2} p_x^2 + \dfrac{1}{2} x^2 + \dfrac{1}{3} x^3 \quad \Leftrightarrow \quad
\begin{cases}
\dot{x} = p_x \
\dot{p}_{x} = - x - x^2
\end{cases} ;.
\label{eq:fish_Ham}
\end{equation}
This dynamical system has a saddle point at the point <span class="math notranslate nohighlight">\((-1,0)\)</span> from which a homoclinic orbit emerges, which surrounds the elliptic point located at the origin. By applying the <span class="math notranslate nohighlight">\(p\)</span>-norm LD with <span class="math notranslate nohighlight">\(p = 1/2\)</span> and integrating all initial conditions for the same time <span class="math notranslate nohighlight">\(\tau = 3\)</span> we clearly observe in Fig. \ref{fig:fish_lds} A) the problems that appear in the detection of phase space structures due to trajectories escaping to infinity in finite time. If we increase <span class="math notranslate nohighlight">\(\tau\)</span> further, very large and NaN values of LDs completely obscure the phase portrait of the system. On the other hand, if now we use the variable integration time LDs with <span class="math notranslate nohighlight">\(\tau = 8\)</span> and we select for the interaction region a circle of radius <span class="math notranslate nohighlight">\(r = 15\)</span> centered at the origin, the homoclininc orbit and the equilibrium points are nicely captured. Moreover, we can extract the stable and unstable manifolds of the system from the sharp ridges in the gradient of the scalar field, due to the fact that the method is non-differentiable at the location of the manifolds.</p>
<div class="figure align-default" id="id8">
<img alt="../_images/LDfixTime_p_05_fishPot_tau_3.png" src="../_images/LDfixTime_p_05_fishPot_tau_3.png" />
<p class="caption"><span class="caption-number">Fig. 35 </span><span class="caption-text">Phase portrait of the “fish potential” Hamiltonian in Eq. \eqref{eq:fish_Ham} revealed by the <span class="math notranslate nohighlight">\(p\)</span>-norm LDs with <span class="math notranslate nohighlight">\(p = 1/2\)</span>. A) Fixed-time integration LDs in Eq. \eqref{eq:Mp_function} with <span class="math notranslate nohighlight">\(\tau = 3\)</span></span><a class="headerlink" href="#id8" title="Permalink to this image">¶</a></p>
</div>
<div class="figure align-default" id="id9">
<img alt="../_images/LD_p_05_fishPot_tau_8.png" src="../_images/LD_p_05_fishPot_tau_8.png" />
<p class="caption"><span class="caption-number">Fig. 36 </span><span class="caption-text">Phase portrait of the “fish potential” Hamiltonian in Eq. \eqref{eq:fish_Ham} revealed by the <span class="math notranslate nohighlight">\(p\)</span>-norm LDs with <span class="math notranslate nohighlight">\(p = 1/2\)</span>. B) Variable-time integration definition of LDs in Eq. \eqref{eq:Mp_vt} with <span class="math notranslate nohighlight">\(\tau = 8\)</span></span><a class="headerlink" href="#id9" title="Permalink to this image">¶</a></p>
</div>
<div class="figure align-default" id="fish-lds">
<img alt="../_images/manifolds_fishPot_tau_8.png" src="../_images/manifolds_fishPot_tau_8.png" />
<p class="caption"><span class="caption-number">Fig. 37 </span><span class="caption-text">Phase portrait of the “fish potential” Hamiltonian in Eq. \eqref{eq:fish_Ham} revealed by the <span class="math notranslate nohighlight">\(p\)</span>-norm LDs with <span class="math notranslate nohighlight">\(p = 1/2\)</span>. C) Invariant stable (blue) and unstable (red) manifolds of the saddle fixed point  extracted from the gradient of the variable time <span class="math notranslate nohighlight">\(M_p\)</span> function.</span><a class="headerlink" href="#fish-lds" title="Permalink to this image">¶</a></p>
</div>
</div>
<div class="section" id="the-h-enon-heiles-hamiltonian-system">
<h3>The H’enon-Heiles Hamiltonian System<a class="headerlink" href="#the-h-enon-heiles-hamiltonian-system" title="Permalink to this headline">¶</a></h3>
<p>We continue illustrating how to apply the method of Lagrangian descriptors to unveil the dynamical skeleton in systems with a high-dimensional phase space by applying this tool to a hallmark Hamiltonian of nonlinear dynamics, the H’enon-Heiles Hamiltonian. This model was introduced in 1964 to study the motion of stars in galaxies \cite{henon1964} and is described by:</p>
<div class="math notranslate nohighlight">
\[\begin{split}{
H = \dfrac{1}{2} \left(p_x^2 + p_y^2\right) + \dfrac{1}{2}\left(x^2 + y^2\right) + x^2y - \dfrac{1}{3} y^3 \quad \Leftrightarrow \quad
\begin{cases}
\dot{x} = p_x \\
\dot{p}_{x} = - x - 2xy \\
\dot{y} = p_y \\
\dot{p}_{y} = - y - x^2 + y^2
\end{cases} \;.
\label{eq:henon_system}
}\end{split}\]</div>
<p>which has four equilibrium points: one minimum located at the origin and three saddle-center points at <span class="math notranslate nohighlight">\((0,1)\)</span> and <span class="math notranslate nohighlight">\((\pm \sqrt{3}/2,-1/2)\)</span>. The potential energy surface is</p>
<div class="math notranslate nohighlight">
\[{
V(x,y) = x^2/2 + y^2/2 + x^2y - y^3/3
}\]</div>
<p>which has a <span class="math notranslate nohighlight">\(\pi/3\)</span> rotational symmetry and is characterized by a central scattering region about the origin and three escape channels, see Fig. \ref{fig:henonHeiles_pes} below for details.</p>
<p>In order to analyze the phase space of the H’enon-Heiles Hamiltonian by means of the variable integration time LDs, we fix an energy <span class="math notranslate nohighlight">\(H = H_0\)</span> of the system and choose an interaction region <span class="math notranslate nohighlight">\(\mathcal{R}\)</span> defined in configuration space by a circle of radius <span class="math notranslate nohighlight">\(15\)</span> centered at the origin. For our analysis we consider the following phase space slices:</p>
<div class="math notranslate nohighlight">
\[\begin{split}{
\begin{eqnarray}
\mathcal{U}^{+}_{y,p_y} &amp; = \left\{(x,y,p_x,p_y) \in \mathbb{R}^4 \;|\; H = H_0 \;,\; x = 0 \;,\; p_x &gt; 0\right\} \\[.1cm]
\mathcal{V}^{+}_{x,p_x} &amp;= \left\{(x,y,p_x,p_y) \in \mathbb{R}^4 \;|\; H = H_0 \;,\; y = 0 \;,\; p_y &gt; 0\right\}
\label{eq:psos}
\end{eqnarray}
}\end{split}\]</div>
<p>Once we have fixed the surfaces of section (SOS) where we want to compute LDs, we select a grid of initial conditions and, after discarding those that are energetically unfeasible, we integrate the remaining conditions both forward and backward in time, and compute LDs using the definition in Eq. \eqref{eq:Mp_vt} with <span class="math notranslate nohighlight">\(p = 1/2\)</span> along the trajectory for the whole fixed integration time or until the initial condition leaves the interaction region <span class="math notranslate nohighlight">\(\mathcal{R}\)</span>, what happens first. The result obtained when the LDs values are plotted will reveal the stable and unstable manifolds and also KAM tori in the surface of section under consideration. Since the stable and unstable manifolds are detected at points where the LD scalar function is non-differentiable, we can directly extract them from the gradient, that is, using <span class="math notranslate nohighlight">\(||\nabla \mathcal{L}_p||\)</span>. We begin by looking at the phase space structures on the SOS <span class="math notranslate nohighlight">\(\mathcal{U}^{+}_{y,p_y}\)</span>. To do so, we fix an energy for the system <span class="math notranslate nohighlight">\(H = 1/12\)</span>, which is below that of the saddle-center equilibrium points. For that energy level, the exit channels of the PES are closed, and therefore, all trajectories are trapped in the scattering region of the central minimum at the origin. We can clearly see in Fig. \ref{fig:henonHeiles_lds} A)-B) that the computation of the <span class="math notranslate nohighlight">\(p\)</span>-norm variable integration time LDs with <span class="math notranslate nohighlight">\(p = 1/2\)</span> using <span class="math notranslate nohighlight">\(\tau = 50\)</span> reveals that the motion of the system is completely regular. The method nicely captures the UPO present in the central region of the PES and also its stable and unstable manifolds which form a homoclininc connection. In order to demonstrate how the intricate details of chaotic motion are captured by LDs, we increase the energy of the system to <span class="math notranslate nohighlight">\(H = 1/3\)</span>. This energy level is now above that of the index-1 saddles of the PES, and consequently, phase space bottlenecks open in the energy manifold allowing trajectories of the system to escape to infinity from the scattering region. When we apply LDs using <span class="math notranslate nohighlight">\(\tau = 10\)</span> on the SOSs defined in Eq. \eqref{eq:psos}, we observe in Figs. \ref{fig:henonHeiles_lds} C)-F) that we can detect with high-fidelity the intricate homoclinic tangle formed by the stable and unstable manifolds of the UPO associated to the upper index-1 saddle of the PES. Moreover, observe that despite the issue of trajectories escaping to infinity in finite time, LDs succeed in revealing the template of geometrical phase space structures that governs transport and escape dynamics from the PES of the H’enon-Heiles Hamiltonian system.</p>
<div class="figure align-default" id="id10">
<img alt="../_images/henonheiles_pot.png" src="../_images/henonheiles_pot.png" />
<p class="caption"><span class="caption-number">Fig. 38 </span><span class="caption-text">Potential energy surface for the H’enon-Heiles system.</span><a class="headerlink" href="#id10" title="Permalink to this image">¶</a></p>
</div>
<div class="figure align-default" id="henonheiles-pes">
<img alt="../_images/hen_conts.png" src="../_images/hen_conts.png" />
<p class="caption"><span class="caption-number">Fig. 39 </span><span class="caption-text">Potential energy surface projected onto XY plane for the H’enon-Heiles system.</span><a class="headerlink" href="#henonheiles-pes" title="Permalink to this image">¶</a></p>
</div>
<div class="figure align-default" id="id11">
<img alt="../_images/LDs_Henon_tau_50_x_0_E_1div12.png" src="../_images/LDs_Henon_tau_50_x_0_E_1div12.png" />
<p class="caption"><span class="caption-number">Fig. 40 </span><span class="caption-text">Phase space structures of the H’enon-Heiles Hamiltonian as revealed by the <span class="math notranslate nohighlight">\(p\)</span>-norm variable integration time LDs with <span class="math notranslate nohighlight">\(p = 1/2\)</span>. A) LDs computed for <span class="math notranslate nohighlight">\(\tau = 50\)</span> in the SOS <span class="math notranslate nohighlight">\(\mathcal{U}^{+}_{y,p_y}\)</span> with energy <span class="math notranslate nohighlight">\(H = 1/12\)</span></span><a class="headerlink" href="#id11" title="Permalink to this image">¶</a></p>
</div>
<div class="figure align-default" id="id12">
<img alt="../_images/Mani_Henon_tau_50_x_0_E_1div12.png" src="../_images/Mani_Henon_tau_50_x_0_E_1div12.png" />
<p class="caption"><span class="caption-number">Fig. 41 </span><span class="caption-text">Gradient of the LD function showing stable and unstable manifold intersections in blue and red respectively.</span><a class="headerlink" href="#id12" title="Permalink to this image">¶</a></p>
</div>
<div class="figure align-default" id="id13">
<img alt="../_images/LDs_Henon_tau_10_x_0_E_1div3.png" src="../_images/LDs_Henon_tau_10_x_0_E_1div3.png" />
<p class="caption"><span class="caption-number">Fig. 42 </span><span class="caption-text">Phase space structures of the H’enon-Heiles Hamiltonian as revealed by the <span class="math notranslate nohighlight">\(p\)</span>-norm variable integration time LDs with <span class="math notranslate nohighlight">\(p = 1/2\)</span>. B) LDs for <span class="math notranslate nohighlight">\(\tau = 10\)</span> in the SOS <span class="math notranslate nohighlight">\(\mathcal{U}^{+}_{y,p_y}\)</span> with energy <span class="math notranslate nohighlight">\(H = 1/3\)</span></span><a class="headerlink" href="#id13" title="Permalink to this image">¶</a></p>
</div>
<div class="figure align-default" id="id14">
<img alt="../_images/Mani_Henon_tau_10_x_0_E_1div3.png" src="../_images/Mani_Henon_tau_10_x_0_E_1div3.png" />
<p class="caption"><span class="caption-number">Fig. 43 </span><span class="caption-text">Gradient of the LD function showing stable and unstable manifold intersections in blue and red respectively.</span><a class="headerlink" href="#id14" title="Permalink to this image">¶</a></p>
</div>
<div class="figure align-default" id="id15">
<img alt="../_images/LDs_Henon_tau_10_y_0_E_1div3.png" src="../_images/LDs_Henon_tau_10_y_0_E_1div3.png" />
<p class="caption"><span class="caption-number">Fig. 44 </span><span class="caption-text">Phase space structures of the H’enon-Heiles Hamiltonian as revealed by the <span class="math notranslate nohighlight">\(p\)</span>-norm variable integration time LDs with <span class="math notranslate nohighlight">\(p = 1/2\)</span>. C) LDs for <span class="math notranslate nohighlight">\(\tau = 10\)</span> in the SOS  <span class="math notranslate nohighlight">\(\mathcal{V}^{+}_{x,p_x}\)</span> with energy <span class="math notranslate nohighlight">\(H = 1/3\)</span></span><a class="headerlink" href="#id15" title="Permalink to this image">¶</a></p>
</div>
<div class="figure align-default" id="henonheiles-lds">
<img alt="../_images/Mani_Henon_tau_10_y_0_E_1div3.png" src="../_images/Mani_Henon_tau_10_y_0_E_1div3.png" />
<p class="caption"><span class="caption-number">Fig. 45 </span><span class="caption-text">Gradient of the LD function showing stable and unstable manifold intersections in blue and red respectively.</span><a class="headerlink" href="#henonheiles-lds" title="Permalink to this image">¶</a></p>
</div>
</div>
</div>
<div class="section" id="stochastic-lagrangian-descriptors">
<h2>Stochastic Lagrangian Descriptors<a class="headerlink" href="#stochastic-lagrangian-descriptors" title="Permalink to this headline">¶</a></h2>
<p>Lagrangian descriptors were extended to stochastic dynamical systems in  \cite{balibrea2016lagrangian}, and our discussion here is taken from this source, where the reader can also find more details. A basic introduction to stochastic differential equations is in the book \cite{Oksendal2003}.</p>
<div class="section" id="preliminary-concepts">
<h3>Preliminary concepts<a class="headerlink" href="#preliminary-concepts" title="Permalink to this headline">¶</a></h3>
<p>\label{sec:pc}</p>
<p>Lagrangian descriptors are a trajectory based diagnostic. Therefore we first need to develop the concepts required to
describe the nature of trajectories of stochastic differential equations (SDEs). We begin by
considering a general system of SDEs expressed in  differential form as follows:</p>
<p>\begin{equation}
\label{SDE}
dX_{t} = b(X_{t},t)dt + \sigma (X_{t},t)dW_{t}, \quad t \in \mathbb{R},
\end{equation}</p>
<p>where <span class="math notranslate nohighlight">\(b(\cdot) \in C^{1}(\mathbb{R}^{n}\times \mathbb{R})\)</span> is the deterministic part, <span class="math notranslate nohighlight">\(\sigma (\cdot) \in C^{1}(\mathbb{R}^{n}\times \mathbb{R})\)</span> is the random forcing, <span class="math notranslate nohighlight">\(W_{t}\)</span> is a Wiener process (also referred to as Brownian motion) whose definition we give later, and <span class="math notranslate nohighlight">\(X_{t}\)</span> is the solution of the equation. All these functions take values in <span class="math notranslate nohighlight">\(\mathbb{R}^{n}\)</span>.</p>
<p>As the notion of solution of a SDE is closely related with the Wiener process, we  state what is meant by <span class="math notranslate nohighlight">\(W(\cdot )\)</span>. This definition is given in \cite{duan2015}, and this reference serves to provide the background for all of the notions in this section. Also, throughout we will use <span class="math notranslate nohighlight">\(\Omega\)</span> to denote the probability space where the Wiener process is defined.</p>
<p><strong>Definition</strong>
\label{def:Wiener}
A real valued stochastic Wiener or Brownian process <span class="math notranslate nohighlight">\(W(\cdot)\)</span> is a stochastic process defined in a probability space <span class="math notranslate nohighlight">\((\Omega , {\cal F},{\cal P})\)</span> which satisfies</p>
<ol class="simple">
<li><p><span class="math notranslate nohighlight">\(W_0 = 0\)</span> (standard Brownian motion),</p></li>
<li><p><span class="math notranslate nohighlight">\(W_t - W_s\)</span>  follows a Normal distribution <span class="math notranslate nohighlight">\(N(0,t-s)\)</span> for all <span class="math notranslate nohighlight">\(t\geq s \geq 0\)</span>,</p></li>
<li><p>for all time <span class="math notranslate nohighlight">\(0 &lt; t_1 &lt; t_2 &lt; ... &lt; t_n\)</span>, the random variables <span class="math notranslate nohighlight">\(W_{t_1}, W_{t_2} - W_{t_1},... , W_{t_n} - W_{t_{n-1}}\)</span> are independent (independent increments).</p></li>
</ol>
<p>Moreover, <span class="math notranslate nohighlight">\(W(\cdot)\)</span> is a real valued two-sided Wiener process if conditions (ii) and (iii) change into</p>
<ol class="simple">
<li><p><span class="math notranslate nohighlight">\(W_t - W_s\)</span> follows a Normal distribution <span class="math notranslate nohighlight">\(N(0,|t-s|)\)</span> for all <span class="math notranslate nohighlight">\(t, s \in \mathbb{R}\)</span>,</p></li>
<li><p>for all time <span class="math notranslate nohighlight">\(t_1 , t_2 , ... , t_{2n} \in \mathbb{R}\)</span> such that the intervals <span class="math notranslate nohighlight">\(\lbrace (t_{2i-1},t_{2i}) \rbrace_{i=1}^{n}\)</span> are non-intersecting between them\footnote{With the notation <span class="math notranslate nohighlight">\((t_{2i-1},t_{2i})\)</span> we refer to the interval of points between the values <span class="math notranslate nohighlight">\(t_{2i-1}\)</span> and <span class="math notranslate nohighlight">\(t_{2i}\)</span>, regardless the order of the two extreme values. Also with the assertion we impose that every pair of intervals of the family <span class="math notranslate nohighlight">\(\lbrace (t_{2i-1},t_{2i}) \rbrace_{i=1}^{n}\)</span> has an empty intersection, or alternatively that the union <span class="math notranslate nohighlight">\(\bigcup_{i=1}^{n}(t_{2i-1},t_{2i})\)</span> is conformed by <span class="math notranslate nohighlight">\(n\)</span> distinct intervals over <span class="math notranslate nohighlight">\(\mathbb{R}\)</span>.}, the random variables <span class="math notranslate nohighlight">\(W_{t_1}-W_{t_2}, W_{t_3} - W_{t_4},... , W_{t_{2n-1}} - W_{t_{2n}}\)</span> are independent.</p></li>
</ol>
<p>This method of Lagrangian descriptors  has been developed for deterministic differential equations whose temporal domain is <span class="math notranslate nohighlight">\(\mathbb{R}\)</span>. In this sense it is natural to work with two-sided solutions as well as two-sided Wiener processes. Henceforth, every Wiener process <span class="math notranslate nohighlight">\(W(\cdot )\)</span> considered in the this article will be of this form.</p>
<p>Given that any Wiener process <span class="math notranslate nohighlight">\(W(\cdot )\)</span> is a stochastic process, by definition this is a family of random real variables <span class="math notranslate nohighlight">\(\lbrace W_{t}, t\in \mathbb{R} \rbrace\)</span> in such a way that for each <span class="math notranslate nohighlight">\(\omega \in \Omega\)</span> there exists a mapping
<span class="math notranslate nohighlight">\($ t \longmapsto W_{t}(\omega )\)</span>$
known as the trajectory of a Wiener process.</p>
<p>Analogously to the Wiener process, the solution <span class="math notranslate nohighlight">\(X_{t}\)</span> of the SDE \eqref{SDE} is also a stochastic process. In particular, it is a family of random variables <span class="math notranslate nohighlight">\(\lbrace X_{t}, t\in \mathbb{R} \rbrace\)</span> such that for each <span class="math notranslate nohighlight">\(\omega \in \Omega\)</span>, the trajectory of <span class="math notranslate nohighlight">\(X_{t}\)</span> satisfies
\begin{equation}
\label{Xt}
t \longmapsto X_{t}(\omega ) = X_{0}(\omega ) + \int_{0}^{t} b(X_{s}(\omega ), s)ds + \int_{0}^{t} \sigma (X_{s}(\omega ), s)dW_{s}(\omega ),
\end{equation}
where <span class="math notranslate nohighlight">\(X_{0}:\Omega \rightarrow \mathbb{R}^{n}\)</span> is the initial condition. In addition, as <span class="math notranslate nohighlight">\(b(\cdot)\)</span> and <span class="math notranslate nohighlight">\(\sigma(\cdot)\)</span> are smooth functions, they are locally Lipschitz and this leads to existence and pathwise uniqueness of a local, continuous solution (see \cite{duan15}). That is if any two stochastic processes <span class="math notranslate nohighlight">\(X^1\)</span> and <span class="math notranslate nohighlight">\(X^2\)</span> are local solutions in time of SDE \eqref{SDE}, then <span class="math notranslate nohighlight">\(X^1_t(\omega) = X^2_t(\omega)\)</span> over a time interval <span class="math notranslate nohighlight">\(t \in (t_{i},t_{f})\)</span> and for almost every <span class="math notranslate nohighlight">\(\omega \in \Omega\)</span>.</p>
<p>At each instant of time <span class="math notranslate nohighlight">\(t\)</span>, the deterministic integral <span class="math notranslate nohighlight">\(\int_{0}^{t} b(X_{s}(\omega ))ds\)</span> is defined by the usual Riemann integration scheme since <span class="math notranslate nohighlight">\(b\)</span> is assumed to be a differentiable function. However,  the stochastic integral term is chosen to be defined by the It^{o} integral scheme:
\begin{equation}
\label{Ito}
\int_{0}^{t} \sigma (X_{s}(\omega ),s)dW_{s}(\omega ) = \lim_{N \rightarrow \infty} \sum_{i=0}^{N-1} \sigma (X_{i\frac{t}{N}}(\omega ), it/N) \cdot \left[ W_{(i+1)\frac{t}{N}}(\omega ) - W_{i\frac{t}{N}}(\omega ) \right].
\end{equation}
This scheme will also facilitate the implementation of a numerical method for computing approximations for the solution <span class="math notranslate nohighlight">\(X_{t}\)</span> in the next section.</p>
<p>Once the notion of solution, <span class="math notranslate nohighlight">\(X_{t}\)</span>, of a SDE (\ref{SDE}) is established, it is natural to ask if the same notions and ideas familiar from the study of deterministic differential equations  from the dynamical systems point of view are still valid for SDEs. In particular, we want to consider the notion of hyperbolic trajectory and its stable and unstable manifolds in the context of SDEs. We  also want to consider how such notions would manifest themselves in the context of {\em phase space transport} for SDEs, and the stochastic Lagrangian descriptor will play a key role in considering these questions from a practical point of view.</p>
<p>We first discuss the notion of an invariant set for a SDE.
In the deterministic case the simplest possible invariant set is a single trajectory of the differential equation. More precisely, it is the set of points through which a solution passes.  Building on this construction, an invariant set is a collection of trajectories of different solutions. This is the most basic way to characterize the invariant sets with respect to a deterministic differential equation of the form
\begin{equation}
\label{deterministic_system}
\dot{x} = f(x,t), \quad x \in \mathbb{R}^{n}, \quad t \in \mathbb{R}.
\end{equation}
For verifying the invariance of such sets the solution mapping generated by the vector field is used.  For  deterministic autonomous systems  these are referred to as {\em flows} (or “dynamical systems”) and for deterministic nonautonomous systems they are referred to as {\em processes}. The formal definitions can  be found in \cite{kloe11}.</p>
<p>A similar notion of solution mapping for SDEs is introduced using the notion of a random dynamical system <span class="math notranslate nohighlight">\(\varphi\)</span> (henceforth referred to as RDS) in the context of SDEs. This function <span class="math notranslate nohighlight">\(\varphi\)</span> is also a solution mapping of a SDE that satisfies several conditions, but compared with the solution mappings in the deterministic case, this RDS depends on an extra argument which is the random variable <span class="math notranslate nohighlight">\(\omega \in \Omega\)</span>. Furthermore the random variable <span class="math notranslate nohighlight">\(\omega\)</span> evolves with respect to <span class="math notranslate nohighlight">\(t\)</span> by means of a dynamical system <span class="math notranslate nohighlight">\(\lbrace \theta_{t} \rbrace_{t \in \mathbb{R}}\)</span> defined over the probability space <span class="math notranslate nohighlight">\(\Omega\)</span>.</p>
<p><strong>Definition</strong>
\label{rds}</p>
<p>Let <span class="math notranslate nohighlight">\(\lbrace \theta_{t} \rbrace_{t \in \mathbb{R}}\)</span> be a measure-preserving\footnote{Given the probability measure <span class="math notranslate nohighlight">\(\mathcal{P}\)</span> associated with the space <span class="math notranslate nohighlight">\((\Omega , \mathcal{F},\mathcal{P})\)</span>, this remains invariant under the dynamical system <span class="math notranslate nohighlight">\(\lbrace \theta_{t} \rbrace_{t \in \mathbb{R}}\)</span>. Formally, <span class="math notranslate nohighlight">\(\theta_{t}\mathcal{P} = \mathcal{P}\)</span> for every <span class="math notranslate nohighlight">\(t \in \mathbb{R}\)</span>. This statement means that <span class="math notranslate nohighlight">\(\mathcal{P}(B)=\mathcal{P}(\theta_{t}(B))\)</span> for every <span class="math notranslate nohighlight">\(t \in \mathbb{R}\)</span> and every subset <span class="math notranslate nohighlight">\(B \in \mathcal{F}\)</span>. Indeed for any dynamical system <span class="math notranslate nohighlight">\(\lbrace \theta_{t} \rbrace_{t \in \mathbb{R}}\)</span> defined over the same probability space <span class="math notranslate nohighlight">\(\Omega\)</span> as a Wiener process <span class="math notranslate nohighlight">\(W(\cdot )\)</span>, we have the equality <span class="math notranslate nohighlight">\(W_{s}(\theta_{t}\omega ) = W_{t+s}(\omega )-W_{t}(\omega )\)</span> which implies that <span class="math notranslate nohighlight">\(dW_{s}(\theta_{t}\omega ) = dW_{t+s}(\omega )\)</span> for every <span class="math notranslate nohighlight">\(s,t \in \mathbb{R}\)</span> (see \cite{duan15} for a detailed explanation).} dynamical system defined over <span class="math notranslate nohighlight">\(\Omega\)</span>, and let <span class="math notranslate nohighlight">\(\varphi : \mathbb{R} \times \Omega \times \mathbb{R}^{n} \rightarrow \mathbb{R}^{n}\)</span> be a measurable mapping such that <span class="math notranslate nohighlight">\((t,\cdot , x) \mapsto \varphi (t,\omega ,x)\)</span> is continuous for all <span class="math notranslate nohighlight">\(\omega \in \Omega\)</span>, and the family of functions <span class="math notranslate nohighlight">\(\lbrace \varphi (t,\omega ,\cdot ): \mathbb{R}^{n} \rightarrow \mathbb{R}^{n} \rbrace\)</span> has the cocycle property:</p>
<div class="math notranslate nohighlight">
\[ \varphi (0,\omega ,x)=x \quad \text{and} \quad \varphi (t+s,\omega ,x) = \varphi(t,\theta_{s}\omega,\varphi (s,\omega ,x)) \quad \text{for all } t,s \in \mathbb{R}, \text{ } x \in \mathbb{R}^{n} \text{ and } \omega \in \Omega .\]</div>
<p>Then the mapping <span class="math notranslate nohighlight">\(\varphi\)</span> is a random dynamical system with respect to the stochastic differential equation
<span class="math notranslate nohighlight">\($dX_{t} = b(X_{t})dt + \sigma (X_{t})dW_{t}\)</span>$
if <span class="math notranslate nohighlight">\(\varphi (t,\omega ,x)\)</span> is a solution of the equation.</p>
<p>Analogous to the deterministic case, the definition of invariance with respect to a SDE can be characterized in terms of a RDS. This is an important topic in our consideration of stochastic Lagrangian descriptors. Now we introduce an example of a SDE for which the analytical expression of the RDS is obtained. This will be a benchmark example in our development of stochastic Lagrangian descriptors their relation to stochastic invariant manifolds.</p>
<p><b>Noisy saddle point</b></p>
<p>For the stochastic differential equation</p>
<p>\begin{equation}
\label{noisy_saddle}
\begin{cases} dX_{t} = X_{t}dt + dW_{t}^{1} \ dY_{t} = -Y_{t}dt + dW_{t}^{2} \end{cases}
\end{equation}</p>
<p>where <span class="math notranslate nohighlight">\(W_{t}^{1}\)</span> and <span class="math notranslate nohighlight">\(W_{t}^{2}\)</span> are two different Wiener processes, the solutions take the expressions</p>
<p>\begin{equation}
\label{noisy_saddle_solutions}
X_{t} = e^{t} \left( X_{0}(\omega ) + \int_{0}^{t}e^{-s}dW_{s}^{1}(\omega ) \right) \quad , \quad Y_{t} = e^{-t} \left( Y_{0}(\omega ) + \int_{0}^{t}e^{s}dW_{s}^{2}(\omega ) \right)
\end{equation}</p>
<p>and therefore the random dynamical system <span class="math notranslate nohighlight">\(\varphi\)</span> takes the form</p>
<p>\begin{equation}
\label{noisy_saddle_RDS}
\begin{array}{ccccccccc}
\varphi : &amp; &amp; \mathbb{R} \times \Omega \times \mathbb{R}^{2} &amp; &amp; \longrightarrow &amp; &amp; \mathbb{R}^{2} &amp; &amp; \ &amp; &amp; (t,\omega ,(x,y)) &amp; &amp; \longmapsto &amp; &amp; \left( \varphi_{1}(t,\omega ,x),\varphi_{2}(t,\omega ,y) \right) &amp; = &amp; \left( e^{t} \left( x + \int_{0}^{t}e^{-s}dW_{s}^{1}(\omega ) \right) , e^{-t} \left( y + \int_{0}^{t}e^{s}dW_{s}^{2}(\omega ) \right) \right) . \end{array}
\end{equation}</p>
<p>Notice that this last definition (\ref{rds}) is expressed in terms of SDEs with time-independent coefficients <span class="math notranslate nohighlight">\(b,\sigma\)</span>. For more general SDEs  a definition of nonautonomous RDS is developed in \cite{duan2015}. However, for the remaining examples considered in this article we make use of the already given definition of RDS.</p>
<p>Once we have the notion of RDS, it can be used to describe and detect geometrical structures and determine their influence on the  dynamics of trajectories. Specifically, in clear analogy with the deterministic case, we focus on those trajectories whose expressions do not depend explicitly on time <span class="math notranslate nohighlight">\(t\)</span>, which are referred as {\em random fixed points}. Moreover, their stable and unstable manifolds, which may also depend on the random variable <span class="math notranslate nohighlight">\(\omega\)</span>, are also objects of interest due to their influence on the dynamical behavior of nearby trajectories. Both types of objects are invariant. Therefore we describe a characterization of invariant sets with respect to a SDE by means of an associated RDS.</p>
<p><strong>Definition</strong>
\label{invariant_set}</p>
<p>A non empty collection <span class="math notranslate nohighlight">\(M : \Omega \rightarrow \mathcal{P}(\mathbb{R}^{n})\)</span>, where <span class="math notranslate nohighlight">\(M(\omega ) \subseteq \mathbb{R}^{n}\)</span> is a closed subset for every <span class="math notranslate nohighlight">\(\omega \in \Omega\)</span>, is called an invariant set for a random dynamical system <span class="math notranslate nohighlight">\(\varphi\)</span> if</p>
<p>\begin{equation}
\label{invariance}
\varphi (t,\omega ,M(\omega )) = M(\theta_{t}\omega ) \quad \text{for every } t \in \mathbb{R} \text{ and every } \omega \in \Omega.
\end{equation}</p>
<p>Again, we return to the noisy saddle (\ref{noisy_saddle}), which  is an example of a SDE for which several invariant sets can be easily characterized by means of its corresponding RDS.</p>
<p><strong>Noisy saddle point</strong></p>
<p>For the stochastic differential equations</p>
<p>\begin{equation}
\begin{cases} dX_{t} = X_{t}dt + dW_{t}^{1} \ dY_{t} = -Y_{t}dt + dW_{t}^{2} \end{cases}
\end{equation}
where <span class="math notranslate nohighlight">\(W_{t}^{1}\)</span> and <span class="math notranslate nohighlight">\(W_{t}^{2}\)</span> are two different Wiener processes, the solution mapping <span class="math notranslate nohighlight">\(\varphi\)</span> is given by  the following  expression</p>
<div class="math notranslate nohighlight">
\[\begin{split}{
\begin{array}{ccccccccc} 
\varphi : &amp; &amp; \mathbb{R} \times \Omega \times \mathbb{R}^{2} &amp; &amp; \longrightarrow &amp; &amp; \mathbb{R}^{2} &amp; &amp; \\ 
 &amp; &amp; (t,\omega ,(x,y)) &amp; &amp; \longmapsto &amp; &amp; (\varphi_{1}(t,\omega ,x),\varphi_{2}(t,\omega ,y)) &amp; = &amp; \left( e^{t} \left( x + \int_{0}^{t}e^{-s}dW_{s}^{1}(\omega ) \right) , e^{-t} \left( y + \int_{0}^{t}e^{s}dW_{s}^{2}(\omega ) \right) \right) . \end{array}
}\end{split}\]</div>
<p>Notice that this is a decoupled random dynamical system. There exists a solution whose components do not depend on variable <span class="math notranslate nohighlight">\(t\)</span> and are convergent for almost every <span class="math notranslate nohighlight">\(\omega \in \Omega\)</span> as a consequence of the properties of Wiener processes (see \cite{duan15}). This solution has the form:
<span class="math notranslate nohighlight">\($\tilde{X}(\omega) = (\tilde{x}(\omega ),\tilde{y}(\omega )) = \left( - \int_{0}^{\infty}e^{-s}dW_{s}^{1}(\omega ) , \int_{-\infty}^{0}e^{s}dW_{s}^{2}(\omega ) \right) .\)</span>$
Actually, <span class="math notranslate nohighlight">\(\tilde{X}(\omega )\)</span> is a solution because it satisfies the invariance property that we now verify:</p>
<div class="math notranslate nohighlight">
\[\begin{split}{
\label{invariance_x}
\begin{array}{ccl}
\varphi_{1} (t,\omega ,\tilde{x}(\omega )) &amp; = &amp; \displaystyle{e^{t}\left( -\int_{0}^{+\infty}e^{-s}dW^{1}_{s}(\omega ) 
+ \int_{0}^{t}e^{-s}dW^{1}_{s}(\omega ) \right) } = \displaystyle{-\int_{t}^{+\infty}e^{-(s-t)}dW^{1}_{s}(\omega ) }\\ 
&amp; = &amp; \displaystyle{-\int_{0}^{+\infty}e^{-t'}dW^{1}_{t'+t}(\omega) = - 
\int_{0}^{+\infty}e^{-t'}dW^{1}_{t'}(\theta_{t}\omega ) = \tilde{x}(\theta_{t}\omega )} \quad \text{by means of } 
t'=s-t,
\end{array}
}\end{split}\]</div>
<div class="math notranslate nohighlight">
\[\begin{split}{
\label{invariance_y}
\begin{array}{lll}
\varphi_{2} (t,\omega ,\tilde{y}(\omega )) &amp; = &amp; \displaystyle{e^{-t}\left( \int_{-\infty}^{0}e^{s}dW^{2}_{s}(\omega ) + 
\int_{0}^{t}e^{s}dW^{2}_{s}(\omega ) \right)  = \int_{-\infty}^{t}e^{s-t}dW^{2}_{s}(\omega ) = 
\int_{-\infty}^{0}e^{t'}dW^{2}_{t'+t}(\omega )} \\  &amp; = &amp; \displaystyle{ 
\int_{-\infty}^{0}e^{t'}dW^{2}_{t'}(\theta_{t}\omega ) = \tilde{y}(\theta_{t}\omega )} \quad \text{by means of } t'=s-t.
\end{array}
}\end{split}\]</div>
<p>This implies that <span class="math notranslate nohighlight">\(\varphi (t,\omega ,\tilde{X}(\omega )) = \tilde{X}(\theta_{t} \omega)\)</span> for every <span class="math notranslate nohighlight">\(t \in \mathbb{R}\)</span> and every <span class="math notranslate nohighlight">\(\omega \in \Omega\)</span>. Therefore <span class="math notranslate nohighlight">\(\tilde{X}(\omega )\)</span> satisfies the invariance property (\ref{invariance}). This conclusion comes from the fact that <span class="math notranslate nohighlight">\(\tilde{x}(\omega )\)</span> and <span class="math notranslate nohighlight">\(\tilde{y}(\omega )\)</span> are also invariant under the components <span class="math notranslate nohighlight">\(\varphi_{1}\)</span> and <span class="math notranslate nohighlight">\(\varphi_{2}\)</span>, in case these are seen as separate RDSs defined over <span class="math notranslate nohighlight">\(\mathbb{R}\)</span> (see (\ref{invariance_x}) and (\ref{invariance_y}), respectively).</p>
<p>Due to its independence with respect to the time variable <span class="math notranslate nohighlight">\(t\)</span>, it is said that <span class="math notranslate nohighlight">\(\tilde{X}(\omega )\)</span> is a random fixed point of the SDE (\ref{noisy_saddle}), or more commonly a stationary orbit. As the trajectory of <span class="math notranslate nohighlight">\(\tilde{X}(\omega )\)</span> (and separately its components <span class="math notranslate nohighlight">\(\tilde{x}(\omega )\)</span> and <span class="math notranslate nohighlight">\(\tilde{y}(\omega )\)</span>) is proved to be an invariant set, it is straightforward to check that the two following subsets of <span class="math notranslate nohighlight">\(\mathbb{R}^{2}\)</span>,</p>
<div class="math notranslate nohighlight">
\[\mathcal{S}(\omega ) = \lbrace (x,y) \in \mathbb{R}^{2} : x = \tilde{x}(\omega ) \rbrace \quad , \quad \mathcal{U}(\omega ) = \lbrace (x,y) \in \mathbb{R}^{2} : y = \tilde{y}(\omega ) \rbrace \]</div>
<p>are also invariant with respect to the RDS <span class="math notranslate nohighlight">\(\varphi\)</span>. Similarly to the deterministic setting, these are referred to as the stable and unstable manifolds of the stationary orbit respectively. Additionally, in order to prove the separating nature of these two manifolds and the stationary orbit with respect to their nearby trajectories, let’s consider any other solution <span class="math notranslate nohighlight">\((\overline{x}_{t},\overline{y}_{t})\)</span> of the noisy saddle with initial conditions at time <span class="math notranslate nohighlight">\(t=0\)</span>,</p>
<div class="math notranslate nohighlight">
\[\overline{x}_{0} = \tilde{x}(\omega ) + \epsilon_{1}(\omega ) , \quad \overline{y}_{0} = \tilde{y}(\omega ) + \epsilon_{2}(\omega ), \quad \text{being } \epsilon_{1}(\omega ), \epsilon_{2}(\omega ) \text{ two random variables.}\]</div>
<p>If the corresponding RDS <span class="math notranslate nohighlight">\(\varphi\)</span> is applied to compare the evolution of this solution <span class="math notranslate nohighlight">\((\overline{x}_{t},\overline{y}_{t})\)</span> and the stationary orbit, there arises an exponential dichotomy:</p>
<div class="math notranslate nohighlight">
\[ (\overline{x}_{t},\overline{y}_{t}) - (\tilde{x}(\theta_{t}\omega ),\tilde{y}(\theta_{t}\omega )) = \varphi (t,\omega ,(\overline{x}_{0},\overline{y}_{0})) - \varphi (t,\omega ,(\tilde{x}(\omega ),\tilde{y}(\omega ))) \]</div>
<div class="math notranslate nohighlight">
\[= \left( e^{t}\left[ \overline{x}_{0} + \int_{0}^{t}e^{-s}dW_{s}^{1}(\omega ) - \tilde{x}(\omega ) - \int_{0}^{t}e^{-s}dW_{s}^{1}(\omega ) \right] , e^{-t}\left[ \overline{y}_{0} + \int_{0}^{t}e^{s}dW_{s}^{2}(\omega ) - \tilde{y}(\omega ) - \int_{0}^{t}e^{s}dW_{s}^{2}(\omega ) \right] \right) \]</div>
<div class="math notranslate nohighlight">
\[{
\label{dichotomy}
= \left( e^{t} \left( \tilde{x}(\omega )+\epsilon_{1}(\omega )-\tilde{x}(\omega ) \right) ,e^{-t} \left( \tilde{y}(\omega )+\epsilon_{2}(\omega )-\tilde{y}(\omega ) \right) \right) = \left( \epsilon_{1}(\omega )e^{t},\epsilon_{2}(\omega )e^{-t} \right) .
}\]</div>
<p>Considering that <span class="math notranslate nohighlight">\((\overline{x}_{t},\overline{y}_{t})\)</span> is different from <span class="math notranslate nohighlight">\((\tilde{x}(\omega ),\tilde{y}(\omega ))\)</span> then one of the two cases <span class="math notranslate nohighlight">\(\epsilon_{1} \not \equiv 0\)</span> or <span class="math notranslate nohighlight">\(\epsilon_{2} \not \equiv 0\)</span> holds, let say <span class="math notranslate nohighlight">\(\epsilon_{1} \not = 0\)</span> or <span class="math notranslate nohighlight">\(\epsilon_{2} \not = 0\)</span> for almost every <span class="math notranslate nohighlight">\(\omega \in \Omega\)</span>. In the first case, the distance between both trajectories <span class="math notranslate nohighlight">\((\overline{x}_{t},\overline{y}_{t})\)</span> and <span class="math notranslate nohighlight">\((\tilde{x},\tilde{y})\)</span> increases at an exponential rate in positive time:</p>
<div class="math notranslate nohighlight">
\[{
\label{eq:eq_1}
\Vert \varphi (t,\omega ,(\overline{x}_{t},\overline{y}_{t}))-\varphi (t,\omega ,(\tilde{x},\tilde{y})) \Vert \geq |\epsilon_{1}(\omega )e^{t} | \longrightarrow + \infty \quad \text{when }  t \rightarrow + \infty \text{ and for a.e. } \omega \in \Omega .
}\]</div>
<p>Similarly to this case, when the second option holds the distance between both trajectories increases at a exponential rate in negative time. It does not matter how close the initial condition <span class="math notranslate nohighlight">\((\overline{x}_{0},\overline{x}_{0})\)</span> is from <span class="math notranslate nohighlight">\((\tilde{x}(\omega ),\tilde{y}(\omega ))\)</span> at the initial time <span class="math notranslate nohighlight">\(t=0\)</span>. Actually this same exponentially growing separation can be achieved for any other initial time <span class="math notranslate nohighlight">\(t \not = 0\)</span>. Following these arguments, one can check that the two manifolds <span class="math notranslate nohighlight">\(\mathcal{S}(\omega )\)</span> and <span class="math notranslate nohighlight">\(\mathcal{U}(\omega )\)</span> also exhibit this same separating behaviour as the stationary orbit. Moreover, we remark  that almost surely the stationary orbit is the only solution whose components are bounded.</p>
<p>These facts highlight the distinguished nature of the stationary orbit (and its manifolds) in the sense that it is an isolated solution from the others. Apart from the fact that <span class="math notranslate nohighlight">\((\tilde{x},\tilde{y})\)</span> “moves” in a bounded domain for every <span class="math notranslate nohighlight">\(t \in \mathbb{R}\)</span>, any other trajectory eventually passing through an arbitrary neighborhood of <span class="math notranslate nohighlight">\((\tilde{x},\tilde{y})\)</span> at any given instant of time <span class="math notranslate nohighlight">\(t\)</span>,  leaves the neighborhood and then separates from the stationary orbit in either positive or negative time. Specifically, this separation rate is exponential for the noisy saddle, just in the same way as for the deterministic saddle.</p>
<p>These features are also observed for the trajectories within the stable and unstable manifolds of the stationary orbit, but in a more restrictive manner than <span class="math notranslate nohighlight">\((\tilde{x},\tilde{y})\)</span>. Taking for instance an arbitrary trajectory <span class="math notranslate nohighlight">\((x^{s},y^{s})\)</span> located at <span class="math notranslate nohighlight">\(\mathcal{S}(\omega )\)</span> for every <span class="math notranslate nohighlight">\(t \in \mathbb{R}\)</span>, its first component <span class="math notranslate nohighlight">\(x^{s}_{t}=\tilde{x}(\omega )\)</span> remains bounded for almost every <span class="math notranslate nohighlight">\(\omega \in \Omega\)</span>. In contrast, any other solution passing arbitrarily closed to <span class="math notranslate nohighlight">\((x^{s},y^{s})\)</span> neither being part of <span class="math notranslate nohighlight">\(\mathcal{S}(\omega )\)</span> nor being the stationary orbit, satisfies the previous inequality (\ref{eq_1}) and therefore separates from <span class="math notranslate nohighlight">\(\mathcal{S}(\omega )\)</span> at an exponential rate for increasing time. With this framework we can now introduce the formal definitions of stationary orbit and invariant manifold.</p>
<p><strong>Definition</strong>
\label{stationary_orbit}</p>
<p>A random variable <span class="math notranslate nohighlight">\(\tilde{X}: \Omega \rightarrow \mathbb{R}^{n}\)</span> is called a stationary orbit (random fixed point) for a random dynamical system <span class="math notranslate nohighlight">\(\varphi\)</span> if</p>
<div class="math notranslate nohighlight">
\[\varphi(t, \omega, \tilde{X}(\omega)) = \tilde{X}(\theta_t\omega), \quad \text{for every } t \in \mathbb{R} \text{ and every } \omega \in \Omega .\]</div>
<p>Obviously every stationary orbit <span class="math notranslate nohighlight">\(\tilde{X}(\omega )\)</span> is an invariant set with respect to a RDS as it satisfies Definition \ref{invariant_set}. Among several definitions of invariant manifolds given in the bibliography (for example \cite{arno98}, \cite{boxl89}, \cite{duan15}), which have different formalisms but share the same philosophy, we choose the one given in \cite{duan15} because it adapts to our example in a very direct way.</p>
<p><strong>Definition</strong>
A random invariant set <span class="math notranslate nohighlight">\(M: \Omega \rightarrow \mathcal{P}(\mathbb{R}^{n})\)</span> for a random dynamical system <span class="math notranslate nohighlight">\(\varphi\)</span> is called a <span class="math notranslate nohighlight">\(C^{k}\)</span>-Lipschitz invariant manifold if it can be represented by a graph of a <span class="math notranslate nohighlight">\(C^{k}\)</span> Lipschitz mapping (<span class="math notranslate nohighlight">\(k \geq 1\)</span>)
<span class="math notranslate nohighlight">\($\gamma (\omega , \cdot ):H^{+} \to H^{-}, \quad \text{with direct sum decomposition } H^{+} \oplus H^{-} = \mathbb{R}^{n}\)</span>$
<span class="math notranslate nohighlight">\($\text{such that} \quad M(\omega ) = \lbrace x^{+} \oplus \gamma(\omega ,x^{+}) : x^{+} \in H^{+} \rbrace \quad \text{for every } \omega \in \Omega.\)</span>$</p>
<p>This is a very limited notion of invariant manifold as its formal definition requires the set to be represented by a Lipschitz graph. Anyway, it is consistent with the already established manifolds <span class="math notranslate nohighlight">\(\mathcal{S}(\omega )\)</span> and <span class="math notranslate nohighlight">\(\mathcal{U}(\omega )\)</span> as these can be represented as the graphs of two functions <span class="math notranslate nohighlight">\(\gamma_{s}\)</span> and <span class="math notranslate nohighlight">\(\gamma_{u}\)</span> respectively,</p>
<p>\begin{align}
\begin{array}{ccccc}
\gamma_{s} (\omega , \cdot ) &amp; : &amp; span \lbrace \left( \begin{array}{c} 0 \ 1 \end{array} \right) \rbrace &amp; \longrightarrow &amp; span \lbrace \left( \begin{array}{c} 1 \ 0 \end{array} \right) \rbrace \
&amp; &amp; \left( \begin{array}{c} 0 \ t \end{array} \right) &amp; \longmapsto &amp; \left( \begin{array}{c} \tilde{x}(\omega ) \ 0 \end{array} \right) \end{array}
; \text{and} ;
\begin{array}{ccccc} \gamma_{u} (\omega , \cdot ) &amp; : &amp; span \lbrace \left( \begin{array}{c} 1 \ 0 \end{array} \right) \rbrace &amp; \longrightarrow &amp; span \lbrace \left( \begin{array}{c} 0 \ 1 \end{array} \right) \rbrace \
&amp; &amp; \left( \begin{array}{c} t \ 0 \end{array} \right) &amp; \longmapsto &amp; \left( \begin{array}{c} 0 \ \tilde{y}(\omega ) \end{array} \right) \quad .
\end{array}
\end{align}</p>
<p>Actually the domains of such functions <span class="math notranslate nohighlight">\(\gamma_{s}\)</span> and <span class="math notranslate nohighlight">\(\gamma_{u}\)</span> are the linear subspaces <span class="math notranslate nohighlight">\(E^{s}(\omega )\)</span> and <span class="math notranslate nohighlight">\(E^{u}(\omega )\)</span>, known as the stable and unstable subspaces of the random dynamical system <span class="math notranslate nohighlight">\(\Phi (t,\omega )\)</span>. This last mapping is obtained from linearizing the original RDS <span class="math notranslate nohighlight">\(\varphi\)</span> over the stationary orbit <span class="math notranslate nohighlight">\((\tilde{x},\tilde{y})\)</span>. This result serves as an argument to denote <span class="math notranslate nohighlight">\(\mathcal{S}(\omega )\)</span> and <span class="math notranslate nohighlight">\(\mathcal{U}(\omega )\)</span> as the stable and unstable manifolds of the stationary orbit, not only because these two subsets are invariant under <span class="math notranslate nohighlight">\(\varphi\)</span>, as one can deduce from (\ref{invariance_x}) and (\ref{invariance_y}), but also due to the dynamical behaviour of their trajectories in a neighborhood of the stationary orbit <span class="math notranslate nohighlight">\(\tilde{X}(\omega )\)</span>. Hence the important  characteristic  of <span class="math notranslate nohighlight">\(\tilde{X}(\omega )=(\tilde{x},\tilde{y})\)</span> is not only its independence with respect to the time variable <span class="math notranslate nohighlight">\(t\)</span>; but also the fact  that it exhibits  hyperbolic behaviour with respect to its neighboring trajectories. Considering the hyperbolicity of a given solution, as well as in the deterministic context, means considering  the hyperbolicity of the RDS <span class="math notranslate nohighlight">\(\varphi\)</span> linearized over such solution. Specifically, the Oseledets’ multiplicative ergodic theorem for random dynamical systems (\cite{arno98} and \cite{duan15}) ensures the existence of a Lyapunov spectrum which is necessary to determine whether the stationary orbit <span class="math notranslate nohighlight">\(\tilde{X}(\omega )\)</span> is hyperbolic or not. All these issues are well reported in \cite{duan15}, including the proof that the noisy saddle (\ref{noisy_saddle}) satisfies the Oseledets’ multiplicative ergodic theorem conditions.</p>
<p>Before  implementing the numerical method of Lagrangian descriptors to several examples of SDEs, it is important to remark why random fixed points and their respective stable and unstable manifolds govern the nearby trajectories, and furthermore, how they may influence the dynamics throughout the rest of the domain. These are essential issues in order to describe the global phase space  motion of  solutions of SDEs. However, these questions do not have a simple answer. For instance, in the noisy saddle example (\ref{noisy_saddle}) the geometrical structures arising from the dynamics generated around the stationary orbit are quite similar to the dynamics corresponding to the deterministic saddle point <span class="math notranslate nohighlight">\(\lbrace \dot{x}=x,\dot{y}=-y \rbrace\)</span>. Significantly, the manifolds <span class="math notranslate nohighlight">\(\mathcal{S}(\omega )\)</span> and <span class="math notranslate nohighlight">\(\mathcal{U}(\omega )\)</span> of the noisy saddle form two dynamical barriers for other trajectories in the same way that the manifolds <span class="math notranslate nohighlight">\(\lbrace x = 0 \rbrace\)</span> and <span class="math notranslate nohighlight">\(\lbrace y = 0 \rbrace\)</span> of the deterministic saddle work. This means that for any particular experiment, i.e., for any given <span class="math notranslate nohighlight">\(\omega \in \Omega\)</span>, the manifolds <span class="math notranslate nohighlight">\(\mathcal{S}(\omega )\)</span> and <span class="math notranslate nohighlight">\(\mathcal{U}(\omega )\)</span> are determined and cannot be “crossed” by other trajectories due to the uniqueness of solutions (remember that the manifolds are invariant under the RDS (\ref{noisy_saddle_RDS}) and are comprised of an infinite family of solutions). Also by considering the exponential separation rates reported in (\ref{eq_1}) with the rest of trajectories, the manifolds <span class="math notranslate nohighlight">\(\mathcal{S}(\omega )\)</span> and <span class="math notranslate nohighlight">\(\mathcal{U}(\omega )\)</span> divide the plane <span class="math notranslate nohighlight">\(\mathbb{R}^{2}\)</span> of initial conditions into four qualitatively distinct dynamical regions; therefore providing a phase portrait representation.</p>
<p>Nevertheless it remains to show that such analogy can be found between other SDEs and their corresponding non-noisy deterministic differential equations\footnote{Otherwise if nonlinearity is dominating the behavior of the terms in equation (\ref{SDE}) then the correspondence between the manifolds for <span class="math notranslate nohighlight">\(\Phi (t, \omega )\)</span> to the manifolds for <span class="math notranslate nohighlight">\(\varphi\)</span> needs to be made by means of the local stable and unstable manifold theorem (see \cite{moham99}, Theorem 3.1). Therein it is considered a homeomorphism <span class="math notranslate nohighlight">\(H(\omega )\)</span> which establishes the equivalence of the geometrical structures arising for both sets of manifolds, and as a consequence the manifolds for <span class="math notranslate nohighlight">\(\varphi\)</span> inherit the same dynamics as the ones for <span class="math notranslate nohighlight">\(\Phi (t, \omega )\)</span> but only in a neighborhood of the stationary orbit. In this sense the existence of such manifolds for a nonlinear RDS <span class="math notranslate nohighlight">\(\varphi\)</span> is only ensured locally. Anyway this result provides a very good approximation to the stochastic dynamics of a system, and enables us to discuss the different patterns of behavior of the solutions in the following examples.}. In this direction there is a recent result (\cite{cheng16}, Theorem 2.1) which ensures the equivalence in the dynamics of both kinds of equations when the noisy term <span class="math notranslate nohighlight">\(\sigma\)</span> is additive (i.e., <span class="math notranslate nohighlight">\(\sigma\)</span> does not depend on the solution <span class="math notranslate nohighlight">\(X_{t}\)</span>). Although this was done by means of the most probable phase portrait, a technique that closely resembles the ordinary phase space for deterministic systems, this fact might indicate that such analogy in the dynamics cannot be achieved when the noise does depend explicitly on the solution <span class="math notranslate nohighlight">\(X_{t}\)</span>. Actually any additive noise affects all the particles together at the same magnitude.</p>
<p>Anyway the noisy saddle serves to establish an analogy to the dynamics with the deterministic saddle. One of its features is the contrast between the growth of the components <span class="math notranslate nohighlight">\(X_{t}\)</span> and <span class="math notranslate nohighlight">\(Y_{t}\)</span>, which mainly have a positive and negative exponential growth respectively. We will see that this is graphically captured when applying the stochastic Lagrangian descriptors method to the SDE (\ref{noisy_saddle}) over a domain of the stationary orbit. Moreover when representing the stochastic Lagrangian descriptor values for the noisy saddle, one can observe that the lowest values are precisely located on the manifolds <span class="math notranslate nohighlight">\(\mathcal{S}(\omega )\)</span> and <span class="math notranslate nohighlight">\(\mathcal{U}(\omega )\)</span>. These are manifested as  sharp features indicating a rapid change of the values that the stochastic Lagrangian descriptor assumes. This geometrical structure formed by “local minimums” has a very marked crossed form and it is straightforward to think that the stationary orbit is located at the intersection of the two cross-sections. These statements are supported afterwards by numerical simulations and analytical results.</p>
<p>However there persists an open question about how reliable the stochastic Lagrangian descriptors method is when trying to depict the phase space of an arbitrary stochastic differential equation. This is the main issue concerning this method and has only been partially reported for deterministic dynamical systems in previous articles (\cite{mancho2013lagrangian} and \cite{lopesino2017}). In this last paper it is analytically proven the efficacy of this method for autonomous and non-autonomous Hamiltonian systems. The theoretical idea that supports this assertion is the discontinuity of the transversal derivative of the Lagrangian descriptor function over the manifolds of the corresponding hyperbolic trajectory. Following this idea, these “singular features” arising on the manifolds of a hyperbolic trajectory for a deterministic Hamiltonian system motivates  us to study whether the “abrupt changes” on the stochastic Lagrangian descriptor function represent the location of the manifolds of a stationary orbit or not. Another related question is to determine the size of the random term <span class="math notranslate nohighlight">\(\sigma dW\)</span> in relation to  its influence on  the phase space of the deterministic equation <span class="math notranslate nohighlight">\(dX = b dt\)</span>. The next sections will be dedicated to addressing  these  issues by considering concrete examples of SDEs.</p>
</div>
<div class="section" id="the-stochastic-lagrangian-descriptor">
<h3>The stochastic Lagrangian descriptor<a class="headerlink" href="#the-stochastic-lagrangian-descriptor" title="Permalink to this headline">¶</a></h3>
<p>\label{sec:SLD}</p>
<p>The definition of stochastic Lagrangian descriptors that we introduce here is based on the discretization of the continuous time definition given in Eq. \eqref{eq:Mp_function} that relies on the computation of the <span class="math notranslate nohighlight">\(p\)</span>-norm of trajectories. In fact, this discretization gave rise to a version of LDs that can be used to analyze discrete time dynamical systems (maps), see \cite{carlos2015}. Let <span class="math notranslate nohighlight">\(\{x_i\}^{N}_{i = 
-N}\)</span> denote an orbit of <span class="math notranslate nohighlight">\((2N + 1)\)</span> points, where <span class="math notranslate nohighlight">\(x_i \in \mathbb{R}^n\)</span> and <span class="math notranslate nohighlight">\(N \in \mathbb{N}\)</span> is the number of iterations of the map. Considering the space of orbits as a sequence space, the discrete Lagrangian descriptor was defined in terms of the <span class="math notranslate nohighlight">\(\ell^p\)</span>-norm of an orbit as follows:</p>
<p>\begin{equation}
\displaystyle{MD_p(x_0, N) = \sum^{N-1}<em>{i = -N}\Vert x</em>{i+1} - x_i \Vert_p, \quad p \leq 1.}
\end{equation}
This alternative definition allows us to prove formally the non-differentiability of the <span class="math notranslate nohighlight">\(MD_p\)</span> function through points that belong to invariant manifolds of a hyperbolic trajectory. This fact implies a better visualization of the invariant manifolds as they are detected over areas where the <span class="math notranslate nohighlight">\(MD_p\)</span> function presents abrupt changes in its values.</p>
<p>Now we extend these ideas to the context of stochastic differential equations. For this purpose we consider  a general SDE of the form:</p>
<p>\begin{equation}
dX_t = b(X_t, t)dt + \sigma(X_t, t)dW_t, \quad X_{t_0} = x_0,
\label{eq:stochastic_lagrangian_system}
\end{equation}</p>
<p>where <span class="math notranslate nohighlight">\(X_t\)</span> denotes the solution of the system, <span class="math notranslate nohighlight">\(b(\cdot)\)</span> and <span class="math notranslate nohighlight">\(\sigma(\cdot)\)</span> are Lipschitz functions which ensure uniqueness of solutions and <span class="math notranslate nohighlight">\(W_t\)</span> is a two-sided Wiener process. Henceforth, we make use of the following notation</p>
<p>\begin{equation}
X_{t_j} := X_{t_0+j\Delta t},
\end{equation}</p>
<p>for a given <span class="math notranslate nohighlight">\(\Delta t&gt;0\)</span> small enough and <span class="math notranslate nohighlight">\(j=-N,\cdots ,-1,0,1, \cdots ,N\)</span>.</p>
<p><strong>Definition</strong>
The stochastic Lagrangian descriptor evaluated for SDE \eqref{eq:stochastic_lagrangian_system} with general solution
<span class="math notranslate nohighlight">\(\textbf{X}_{t}(\omega )\)</span> is given by</p>
<p>\begin{equation}
MS_p(\textbf{x}<em>0, t_0, \tau, \omega) = \sum^{N-1}</em>{i = -N} \Vert \textbf{X}<em>{t</em>{i+1}} -
\textbf{X}_{t_i} \Vert_p
\label{eq:MS}
\end{equation}</p>
<p>where <span class="math notranslate nohighlight">\(\lbrace \textbf{X}_{t_{j}} \rbrace_{j=-N}^{N}\)</span> is a discretization of the solution such that
<span class="math notranslate nohighlight">\(\textbf{X}_{t_{-N}} = \textbf{X}_{-\tau}\)</span>, <span class="math notranslate nohighlight">\(\textbf{X}_{t_N} = \textbf{X}_{\tau}\)</span>, <span class="math notranslate nohighlight">\(\textbf{X}_{t_0} = \textbf{x}_{0}\)</span>, for a given <span class="math notranslate nohighlight">\(\omega \in \Omega\)</span>.</p>
<p><strong>Definition</strong>
Obviously every output of the <span class="math notranslate nohighlight">\(MS_p\)</span> function highly depends on the experiment <span class="math notranslate nohighlight">\(\omega \in \Omega\)</span> where <span class="math notranslate nohighlight">\(\Omega\)</span> is the probability space that includes all the possible outcomes of a given phenomena. Therefore in order to analyze the homogeneity of a given set of outputs, we consider a sequence of results of the <span class="math notranslate nohighlight">\(MS_p\)</span> function for the same stochastic equation \eqref{eq:stochastic_lagrangian_system}: <span class="math notranslate nohighlight">\(MS_p(\cdot, \omega_1)\)</span>, <span class="math notranslate nohighlight">\(MS_p(\cdot, \omega_2)\)</span>,
<span class="math notranslate nohighlight">\(\cdots\)</span>, <span class="math notranslate nohighlight">\(MS_p(\cdot, \omega_M)\)</span>. It is feasible that the following relation holds</p>
<p>\begin{equation}
d(MS_p(\cdot, \omega_i), MS_p(\cdot, \omega_j)) &lt; \delta, \quad \text{for all } i,j,
\label{eq:deterministic_tol}
\end{equation}</p>
<p>where <span class="math notranslate nohighlight">\(d\)</span> is a metric that measures the similarity between two matrices (for instance the Frobenius norm <span class="math notranslate nohighlight">\(\Vert A-B \Vert_F = 
\sqrt{Tr((A-B)\cdot (A-B)^T)}\)</span>) and <span class="math notranslate nohighlight">\(\delta\)</span> is a positive tolerance. Nevertheless for general stochastic differential equations, expression (\eqref{eq:deterministic_tol}) does not usually hold. Alternatively if the elements of the sequence of matrices <span class="math notranslate nohighlight">\(MS_p(\cdot, \omega_1)\)</span>, <span class="math notranslate nohighlight">\(MS_p(\cdot, \omega_2)\)</span>, <span class="math notranslate nohighlight">\(\cdots\)</span>, <span class="math notranslate nohighlight">\(MS_p(\cdot, \omega_M)\)</span> do not have much similarity to each other, it may be of more use to define the mean of the outputs</p>
<p>\begin{equation}
\displaystyle{\mathbb{E} \left[ MS_p(\cdot, \omega) \right] = \left(
\frac{MS_p(\cdot, \omega_1) + MS_p(\cdot, \omega_2) + \cdots +
MS_p(\cdot, \omega_M)}{M}\right) ,}
\label{eq:mean_MSp_value}
\end{equation}</p>
<p>for a sufficiently large number of experiments <span class="math notranslate nohighlight">\(M\)</span>. Since the solution of a SDE is affected by the noise term, the phase portrait of the studied SDE for an arbitrary <span class="math notranslate nohighlight">\(\omega\)</span> becomes unpredictable and one can only refer to places where hyperbolic trajectories and invariant manifolds are likely located. This way of understanding the geometry of transport for SDEs is similar in spirit as the one explained in \cite{banisch16} where the authors provide an alternative method for revealing coherent sets from Lagrangian trajectory data.</p>
</div>
</div>
<div class="section" id="numerical-simulation-of-the-stochastic-lagrangian-descriptor">
<h2>Numerical Simulation of the Stochastic Lagrangian Descriptor<a class="headerlink" href="#numerical-simulation-of-the-stochastic-lagrangian-descriptor" title="Permalink to this headline">¶</a></h2>
<p>\label{sec:num}</p>
<p>In this section we describe the stochastic Lagrangian descriptor method that can be used to numerically solve and visualize the geometrical structures of SDEs. Consider a general <span class="math notranslate nohighlight">\(n\)</span>-dimensional SDE of the form
\begin{equation}
dX^j_t = b^j(X_t, t)dt + \sum^m_{k=1}\sigma^j_k(X_t, t)dW^k_t, \quad X_{t_0} = x_0 \in \mathbb{R}^n, \quad j=1,\cdots ,n
\end{equation}
where <span class="math notranslate nohighlight">\(X_t = (X^1_t, \cdots , X^n_t)\)</span> and <span class="math notranslate nohighlight">\(W^1_t, \cdots, W^m_t\)</span> are <span class="math notranslate nohighlight">\(m\)</span> independent Wiener processes.
If the time step <span class="math notranslate nohighlight">\(\Delta t\)</span> is firstly fixed, then the temporal grid <span class="math notranslate nohighlight">\(t_p = t_0 + p\Delta t\)</span> (<span class="math notranslate nohighlight">\(p \in \mathbb{Z}\)</span>) is already determined and we arrive to the difference equation
\begin{equation}
X^j_{t+\Delta t} = X^j_t + b^j(X_t, t)\Delta t + \sum^m_{k=1} \sigma^j_k(X_t, t)dW^k_t.
\end{equation}
This scheme is referred to as the Euler-Marayuma method for solving a single path of the SDE. If the stochastic part is removed from the equation, then we obtain the classical Euler method. Suppose <span class="math notranslate nohighlight">\(X_{t_p}\)</span> is the solution of the SDE and
<span class="math notranslate nohighlight">\(\tilde{X}_{t_p}\)</span> its numerical approximation at any time <span class="math notranslate nohighlight">\(t_p\)</span>. Since both of them are random variables, the accuracy of the method must be determined in probabilistic terms. With this aim, the following definition is introduced.</p>
<p><strong>Definition</strong>
A stochastic numerical method has an  order of convergence equal to <span class="math notranslate nohighlight">\(\gamma\)</span> if there exists a constant <span class="math notranslate nohighlight">\(C&gt;0\)</span> such that</p>
<p>\begin{equation}
\mathbb{E} \left[ X_{t_p} - \tilde{X}_{t_p} \right] \leq C \Delta t^{\gamma},
\end{equation}
for any arbitrary <span class="math notranslate nohighlight">\(t_p = t_0 + p\Delta t\)</span> and <span class="math notranslate nohighlight">\(\Delta t\)</span> small enough.</p>
<p>Indeed, the Euler-Maruyama method has an order of convergence equal to <span class="math notranslate nohighlight">\(1/2\)</span> (see \cite{kloeden2013numerical} for further details).</p>
<div class="section" id="the-noisy-saddle">
<h3>The noisy saddle<a class="headerlink" href="#the-noisy-saddle" title="Permalink to this headline">¶</a></h3>
<p>The noisy saddle is a fundamental benchmark for assessing numerical methods for revealing phase space structures. Its main value is in the simplicity of the expressions taken by the components of the stationary orbit and its  corresponding stable and unstable manifolds. From these one clearly observes the exponential separation rates between particles passing
near the manifolds. Now for the stochastic differential equations</p>
<p>\begin{equation}
\label{eq:general_noisy}
\begin{cases}
dX_t = a_1X_t dt + b_1dW^1_t \
dY_t = -a_2Y_t dt + b_2dW^2_t
\end{cases}
\end{equation}</p>
<p>it is straightforward to check that the only stationary orbit takes the expression</p>
<p>\begin{equation}
\widetilde{X}(\omega ) = \left( \tilde{x}(\omega ), \tilde{y}(\omega ) \right) = \left(
-\int_{0}^{\infty}e^{-a_{1}s} b_1dW^1_t(\omega ) , \int_{-\infty}^{0}e^{b_{1}s}
b_2dW^2_t(\omega ) \right)
\end{equation}</p>
<p>where <span class="math notranslate nohighlight">\(a_{1},a_{2},b_{1},b_{2} \in \mathbb{R}\)</span> are constants and <span class="math notranslate nohighlight">\(a_{1},a_{2}&gt;0\)</span>. Its corresponding stable and unstable manifolds are</p>
<p>\begin{equation}
\mathcal{S}(\omega ) = \lbrace (x,y) \in \mathbb{R}^{2} : x = \tilde{x}(\omega ) \rbrace , \quad
\mathcal{U}(\omega ) = \lbrace (x,y) \in \mathbb{R}^{2} : y = \tilde{y}(\omega ) \rbrace .
\end{equation}</p>
<p>These play a very relevant role as dynamical barriers for the particles tracked by the RDS, which is generated by the SDE (\ref{eq:general_noisy}). This fact has been justified in the previous section, but can be analytically demonstrated when computing the stochastic Lagrangian descriptor (\ref{eq:MS}) for the solution of the noisy saddle.</p>
<p>According to the notation used for the definition of SLD</p>
<div class="math notranslate nohighlight">
\[{ 
MS_p (\mathbf{x}_0, t_0, \tau, \omega) = \sum_{i = -N}^{N-1} \Vert \mathbf{X}_{t_{i+1}} - \mathbf{X}_{t_i} \Vert_p
}\]</div>
<p>at which the components of the solution satisfy the initial conditions <span class="math notranslate nohighlight">\(\textbf{X}_{t_{0}}= \left( X_{t_{0}},Y_{t_{0}} 
\right) = (x_{0},y_{0}) = \textbf{x}_{0}\)</span>, these take the expressions</p>
<p>\begin{equation}
\label{general_noisy_saddle_solutions}
X_{t} = e^{a_{1}t} \left( x_{0} + \int_{0}^{t}e^{-a_{1}s}b_{1}dW_{s}^{1} \right) \quad , \quad Y_{t} = e^{-a_{2}t}
\left( y_{0} + \int_{0}^{t}e^{a_{2}s}b_{2}dW_{s}^{2}(\omega ) \right)
\end{equation}</p>
<p>and the temporal nodes satisfy the rule <span class="math notranslate nohighlight">\(t_{i} = t_{0} + i\Delta t\)</span> with <span class="math notranslate nohighlight">\(t_{0}\)</span> and <span class="math notranslate nohighlight">\(\Delta t\)</span> already given. Now it is possible to compute analytically the increments <span class="math notranslate nohighlight">\(\Vert \textbf{X}_{t_{i+1}} - \mathbf{X}_{t_i} \Vert_p = \vert X_{t_{i+1}} - X_{t_i} \vert^{p} + \vert Y_{t_{i+1}} - Y_{t_i} \vert^{p}\)</span>:</p>
<div class="math notranslate nohighlight">
\[\left| X_{t_{i+1}} - X_{t_i} \right|^{p} = \left| e^{a_{1}t_{i+1}} \left( x_{0} + 
\int_{0}^{t_{i+1}}e^{-a_{1}s}b_{1}dW_{s}^{1} \right) - e^{a_{1}t_{i}} \left( x_{0} + 
\int_{0}^{t_{i}}e^{-a_{1}s}b_{1}dW_{s}^{1} \right) \right|^{p}\]</div>
<div class="math notranslate nohighlight">
\[= \left| e^{a_{1}t_{i}}\left( e^{a_{1}\Delta t} - 1 \right) \left[ x_{0} + \int_{0}^{t_{i}}e^{-a_{1}s}b_{1}dW_{s}^{1} 
\right] + e^{a_{1}(t_{i}+\Delta t)} \int_{t_{i}}^{t_{i}+\Delta t}e^{-a_{1}s}b_{1}dW_{s}^{1} \right|^{p}\]</div>
<div class="math notranslate nohighlight">
\[= \left| e^{a_{1}t_{i}}\left( e^{a_{1}\Delta t} - 1 \right) \left[ x_{0} + 
\int_{0}^{t_{i}}e^{-a_{1}s}b_{1}dW_{s}^{1} \right] + e^{a_{1}\Delta t}b_{1}dW_{t_{i}}^{1} \right|^{p} \text{(by applying 
It\^{o} formula (\ref{Ito})).}\]</div>
<p>Moreover for large values of <span class="math notranslate nohighlight">\(t_{i}\)</span> such that <span class="math notranslate nohighlight">\(e^{a_{1}t_{i}} \gg e^{a_{1}\Delta t}\)</span> and taking into account that <span class="math notranslate nohighlight">\(dW_{t_{i}}^{1}\)</span> is finite almost surely, we can consider the following approximation
\begin{equation}
\label{x_increments}
\left| X_{t_{i+1}} - X_{t_i} \right|^{p} \hspace{0.1cm} \approx \hspace{0.1cm} e^{a_{1}t_{i}\cdot p}\left|
e^{a_{1}\Delta t} - 1 \right|^{p} \left| x_{0} + \int_{0}^{t_{i}}e^{-a_{1}s}b_{1}dW_{s}^{1} \right|^{p}.
\end{equation}</p>
<p>By following these arguments, one can get an analogous result for the second component <span class="math notranslate nohighlight">\(Y_{t}\)</span>:
<span class="math notranslate nohighlight">\($\left| Y_{t_{i+1}} - Y_{t_i} \right|^{p} = \left| e^{-a_{2}t_{i}}\left( e^{-a_{2}\Delta t} - 1 \right) \left[ 
y_{0} + \int_{0}^{t_{i}}e^{a_{2}s}b_{2}dW_{s}^{2} \right] + e^{-a_{2}\Delta t}b_{2}dW_{t_{i}}^{2} \right|^{p},\)</span>$
which for small values of <span class="math notranslate nohighlight">\(t_{i}\)</span>, such that <span class="math notranslate nohighlight">\(e^{-a_{2}t_{i}} \gg e^{-a_{2}\Delta t}\)</span>, this approximation can be further simplified as follows</p>
<p>\begin{equation}
\label{y_increments}
\left| Y_{t_{i+1}} - Y_{t_i} \right|^{p} \hspace{0.1cm} \approx \hspace{0.1cm} e^{-a_{2}t_{i}\cdot p}\left|
e^{-a_{2}\Delta t} - 1 \right|^{p} \left| y_{0} + \int_{0}^{t_{i}}e^{a_{2}s}b_{2}dW_{s}^{2} \right|^{p}.
\end{equation}</p>
<p>Once the analytic expression of the SLD applied to the noisy saddle (\ref{eq:general_noisy}) is known, it can be proved that the stable and unstable manifolds of the stationary orbit are manifested as singularities of the SLD function over any given domain of initial conditions containing the stationary orbit. This fact implies that the SLD method realizes a procedure to detect these geometrical objects and, consequently, provides a phase portrait representation of the dynamics generated by the noisy saddle. In the same way as described in \cite{mancho2013lagrangian}, we refer to singularities as points of the domain of spatial  initial conditions where the derivative of the SLD is not defined. The paradigm example of the mathematical manifestation of singularities of the LD on stable and unstable manifolds of hyperbolic trajectories is provided by the scalar function <span class="math notranslate nohighlight">\(|\cdot |^{p}\)</span> with <span class="math notranslate nohighlight">\(p \in (0,1]\)</span>. This function is  singular, alternatively non-differentiable, at those points where its argument is  zero. Graphically this feature is observed as sharp changes in the representation of the SLD values, where the contour lines concentrate in a very narrow space.
In this particular example we are able to explicitly identify within the expression of the SLD  the terms that are largest in magnitude. In other words, we are able to identify the terms whose particular singularities determine the non-differentiability of the entire sum\footnote{Note that the differentiability of the SLD is analyzed with respect to the components of the initial conditions <span class="math notranslate nohighlight">\((x_{0},y_{0})\)</span>, as the experiment <span class="math notranslate nohighlight">\(\omega \in \Omega\)</span> and the starting point <span class="math notranslate nohighlight">\(t_{0}\)</span> are previously fixed.}. This is better understandable if the expression of the SLD is divided into two sums</p>
<div class="math notranslate nohighlight">
\[{
MS_p(\mathbf{x}_0, t_0, \tau, \omega) = \sum_{i = -N}^{N-1} \Vert \mathbf{X}_{t_{i+1}} - 
\mathbf{X}_{t_i} \Vert_p = \sum^{N-1}_{i = -N} \vert X_{t_{i+1}} - X_{t_i} \vert^{p} + \sum^{N-1}_{i = -N} \vert 
Y_{t_{i+1}} - Y_{t_i} \vert^{p}
}\]</div>
<p>The highest order term within the first sum is <span class="math notranslate nohighlight">\(\left| X_{t_{N}} - X_{t_{N-1}} \right|^{p} = \left| X_{\tau } - X_{\tau - \Delta t} \right|^{p}\)</span>, which according to (\ref{x_increments}) is approximated by</p>
<p>\begin{equation}
\label{higher_order_x}
\left| X_{\tau } - X_{\tau - \Delta t} \right|^{p} \hspace{0.1cm} \approx \hspace{0.1cm} e^{a_{1}(\tau - \Delta
t)\cdot p}\left| e^{a_{1}\Delta t} - 1 \right|^{p} \left| x_{0} + \int_{0}^{\tau - \Delta t}e^{-a_{1}s}b_{1}dW_{s}^{1}
\right|^{p} \quad \text{for enough large values of } \tau .
\end{equation}</p>
<p>Similarly the highest order term within the second sum is <span class="math notranslate nohighlight">\(\left| Y_{t_{-N+1}} - Y_{t_{-N}} \right|^{p} = \left| 
Y_{-\tau +\Delta t} - Y_{-\tau } \right|^{p}\)</span>, approximated by</p>
<p>\begin{equation}
\label{higher_order_y}
\left| Y_{-\tau +\Delta t} - Y_{-\tau } \right|^{p} \hspace{0.1cm}
\approx \hspace{0.1cm} e^{a_{2}\tau \cdot p}\left| e^{-a_{2}\Delta t} - 1 \right|^{p} \left| y_{0} -
\int_{-\tau}^{0}e^{a_{2}s}b_{2}dW_{s}^{2} \right|^{p} \quad \text{for enough large values of } \tau .
\end{equation}</p>
<p>Consequently, it is evident that the sharper features will be located closed to the points where these two last
quantities (\ref{higher_order_x}), (\ref{higher_order_y}) are zero. In other words where the initial condition
<span class="math notranslate nohighlight">\((x_{0},y_{0})\)</span> satisfies one of the two following</p>
<div class="math notranslate nohighlight">
\[x_{0} = - \int_{0}^{\tau - \Delta t}e^{-a_{1}s}b_{1}dW_{s}^{1} \quad \text{or} \quad y_{0} = 
\int_{-\tau}^{0}e^{a_{2}s}b_{2}dW_{s}^{2} \quad \text{for enough large values of } \tau .\]</div>
<p>This statement is in agreement with the distinguished nature of the manifolds of the stationary orbit discussed in the previous section. Note also that the two quantities for <span class="math notranslate nohighlight">\(x_{0}\)</span> and <span class="math notranslate nohighlight">\(y_{0}\)</span> converge to the coordinates of the stationary orbit <span class="math notranslate nohighlight">\((\tilde{x}(\omega ),\tilde{y}(\omega ))\)</span> with <span class="math notranslate nohighlight">\(\tau\)</span> tending to infinity. These features are observed in Figure \ref{fig:saddle}, where the sharpness of the SLD representation highlights the location of the stable and unstable manifolds.</p>
<p>The intersection of the two “singular” curves  represents the position of the stationary orbit <span class="math notranslate nohighlight">\((\tilde{x}(\omega ),\tilde{y}(\omega ))\)</span> for a given <span class="math notranslate nohighlight">\(\omega \in \Omega\)</span>. This fact is validated by the depiction of the stationary orbit, whose components have been computed separately from the SLD, and using the same output of the Wiener process.</p>
<div class="figure align-default" id="id16">
<img alt="../_images/fig1a.png" src="../_images/fig1a.png" />
<p class="caption"><span class="caption-number">Fig. 46 </span><span class="caption-text">Figure A) from  \cite{balibrea2016lagrangian} showing two different experiments representing contours of <span class="math notranslate nohighlight">\(MS_p\)</span> for <span class="math notranslate nohighlight">\(p=0.1\)</span> and <span class="math notranslate nohighlight">\(\tau=15\)</span>. The contours of <span class="math notranslate nohighlight">\(MS_p\)</span> are computed on a 1200$\times$1200 points grid of initial conditions and the time step for integration of the vector field is chosen to be <span class="math notranslate nohighlight">\(\Delta t= 0.05\)</span>. The magenta colored point corresponds to the location of the stationary orbit for each experiment. The chosen parameters are <span class="math notranslate nohighlight">\(a_1 = a_2 = b_2 = 1\)</span> and <span class="math notranslate nohighlight">\(b_1 = -1\)</span>.</span><a class="headerlink" href="#id16" title="Permalink to this image">¶</a></p>
</div>
<div class="figure align-default" id="saddle">
<img alt="../_images/fig1b.png" src="../_images/fig1b.png" />
<p class="caption"><span class="caption-number">Fig. 47 </span><span class="caption-text">Figure B) from  \cite{balibrea2016lagrangian} showing two different experiments representing contours of <span class="math notranslate nohighlight">\(MS_p\)</span> for <span class="math notranslate nohighlight">\(p=0.1\)</span> and <span class="math notranslate nohighlight">\(\tau=15\)</span>. The contours of <span class="math notranslate nohighlight">\(MS_p\)</span> are computed on a 1200$\times$1200 points grid of initial conditions and the time step for integration of the vector field is chosen to be <span class="math notranslate nohighlight">\(\Delta t= 0.05\)</span>. The magenta colored point corresponds to the location of the stationary orbit for each experiment. The chosen parameters are <span class="math notranslate nohighlight">\(a_1 = a_2 = b_2 = 1\)</span> and <span class="math notranslate nohighlight">\(b_1 = -1\)</span>.</span><a class="headerlink" href="#saddle" title="Permalink to this image">¶</a></p>
</div>
<p>\begin{remark}
Due to the properties of It^{o} integrals, see for instance \cite{duan15}, the components of the stationary orbit satisfy
<span class="math notranslate nohighlight">\($\mathbb{E} \left[ \tilde{x}(\omega ) \right] = \mathbb{E} \left[ - \int_{0}^{\infty}e^{-s}dW_{s}^{1} \right] = 0 
\quad , \quad \mathbb{E} \left[ \tilde{y}(\omega ) \right] = \mathbb{E} \left[ \int_{-\infty}^{0}e^{s}dW_{s}^{2} \right] 
= 0,\)</span>$</p>
<div class="math notranslate nohighlight">
\[\mathbb{V} \left[ \tilde{x}(\omega ) \right] = \mathbb{E} \left[ \tilde{x}(\omega )^{2} \right] = \mathbb{E} \left[ 
\int_{0}^{\infty}e^{-2s}ds \right] = \frac{1}{2} \quad , \quad \mathbb{V} \left[ \tilde{y}(\omega ) \right] = \mathbb{E} 
\left[ \tilde{y}(\omega )^{2} \right] = \mathbb{E} \left[ \int_{-\infty}^{0}e^{2s}ds \right] = \frac{1}{2}.\]</div>
<p>This means that the stationary orbit $ (\tilde{x}(\omega ),\tilde{y}(\omega ))$ is highly probable to be located closed to the origin of coordinates <span class="math notranslate nohighlight">\((0,0)\)</span>, and  this feature is displayed in Figure \ref{fig:saddle}. This result gives more evidences and supports the similarities between the stochastic differential equation (\ref{noisy_saddle}) and the deterministic analogue system <span class="math notranslate nohighlight">\(\lbrace \dot{x}=x, \hspace{0.1cm} \dot{y}=-y \rbrace\)</span> whose only fixed point is <span class="math notranslate nohighlight">\((0,0)\)</span>.
\end{remark}</p>
<p>Therefore we can assert that the stochastic Lagrangian descriptor is a technique that provides a phase portrait representation of the dynamics generated by the noisy saddle equation (\ref{eq:general_noisy}). Next we apply this same technique to further examples.</p>
</div>
<div class="section" id="the-stochastically-forced-duffing-oscillator">
<h3>The Stochastically forced Duffing Oscillator<a class="headerlink" href="#the-stochastically-forced-duffing-oscillator" title="Permalink to this headline">¶</a></h3>
<p>\label{sec:examp}</p>
<p>Another classical problem is that of the Duffing oscillator. The deterministic version is given by
\begin{equation}
\label{eq:duffing_determ}
\ddot{x} = \alpha \dot{x} + \beta x + \gamma x^3 + \epsilon \cos(t).
\end{equation}
If <span class="math notranslate nohighlight">\(\epsilon = 0\)</span> the Duffing equation becomes time-independent, meanwhile for <span class="math notranslate nohighlight">\(\epsilon \neq 0\)</span> the oscillator is a time-dependent system, where <span class="math notranslate nohighlight">\(\alpha\)</span> is  the damping parameter, <span class="math notranslate nohighlight">\(\beta\)</span> controls the rigidity of the system and <span class="math notranslate nohighlight">\(\gamma\)</span> controls the size of the nonlinearity of the restoring force. The stochastically forced Duffing
equation is studied in \cite{datta01} and can be written as follows:</p>
<p>\begin{equation}
\begin{cases}
dX_t = \alpha Y_t, \
dY_t = (\beta X_t + \gamma X^3_t)dt + \epsilon dW_t.
\end{cases}
\end{equation}</p>
<p>For our numerical experiments we have selected <span class="math notranslate nohighlight">\(\alpha = \beta = 1\)</span>, <span class="math notranslate nohighlight">\(\gamma = -1\)</span> and <span class="math notranslate nohighlight">\(\epsilon = 0.25\)</span>. The results of three different experiments (let say three different samples of <span class="math notranslate nohighlight">\(\omega_{1},\omega_{2},\omega_{3} \in \Omega\)</span>) are shown in Figure \ref{fig:duffing}.</p>
<div class="figure align-default" id="id17">
<img alt="../_images/fig2a.png" src="../_images/fig2a.png" />
<p class="caption"><span class="caption-number">Fig. 48 </span><span class="caption-text">Figure A) from  \cite{balibrea2016lagrangian}  showing three different experiments representing <span class="math notranslate nohighlight">\(MS_p\)</span> contours for <span class="math notranslate nohighlight">\(p=0.5\)</span> over a grid of initial conditions.</span><a class="headerlink" href="#id17" title="Permalink to this image">¶</a></p>
</div>
<div class="figure align-default" id="id18">
<img alt="../_images/fig2b.png" src="../_images/fig2b.png" />
<p class="caption"><span class="caption-number">Fig. 49 </span><span class="caption-text">Figure B) from  \cite{balibrea2016lagrangian}  showing three different experiments representing <span class="math notranslate nohighlight">\(MS_p\)</span> contours for <span class="math notranslate nohighlight">\(p=0.5\)</span> over a grid of initial conditions.</span><a class="headerlink" href="#id18" title="Permalink to this image">¶</a></p>
</div>
<div class="figure align-default" id="id19">
<img alt="../_images/fig2c.png" src="../_images/fig2c.png" />
<p class="caption"><span class="caption-number">Fig. 50 </span><span class="caption-text">Figure C) from  \cite{balibrea2016lagrangian}  showing three different experiments representing <span class="math notranslate nohighlight">\(MS_p\)</span> contours for <span class="math notranslate nohighlight">\(p=0.5\)</span> over a grid of initial conditions. d) The last image corresponds to the <span class="math notranslate nohighlight">\(M_p\)</span> function for equation \eqref{eq:duffing_determ} and <span class="math notranslate nohighlight">\(p=0.75\)</span>. All these pictures were computed for <span class="math notranslate nohighlight">\(\tau=15\)</span>, and over a <span class="math notranslate nohighlight">\(1200 \times 1200\)</span> points grid. The time step for integration of the vector field was chosen to be <span class="math notranslate nohighlight">\(\Delta t = 0.05\)</span>.</span><a class="headerlink" href="#id19" title="Permalink to this image">¶</a></p>
</div>
</div>
</div>
</div>


              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="chapter2_2.html" title="previous page">An Informal Introduction to  Ideas Related to KAM (Kolmogorov-Arnold-Moser) Theory</a>
    <a class='right-next' id="next-link" href="examples.html" title="next page">Computing the Lagrangian Descriptors of Nonlinear Dynamical Systems</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By The CHAMPS Project<br/>
        
            &copy; Copyright 2020.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    <script src="../_static/js/index.js"></script>
    
  </body>
</html>